#!/usr/bin/env python3
"""
ä½¿ç”¨ LangChain LCEL (LangChain Expression Language)
å°† PR åˆ†æå’Œå‘é‡æ•°æ®åº“å­˜å‚¨ä¸²è”èµ·æ¥

ä½¿ç”¨ç®¡é“æ“ä½œç¬¦: analyze_pr | save_to_vector_store
æ”¯æŒå¤šç§æ¡†æ¶: langchain, anthropic
"""
import os
import asyncio
import argparse
from datetime import datetime, timedelta
from typing import Dict, Optional, Literal, List

from langchain_core.runnables import RunnableLambda, RunnablePassthrough

from pr_analysis_langchain import PRAnalysisLangChain
from pr_analysis_anthropic import PRAnalysisAnthropic
from vector_store import VectorStoreManager
from database import DatabaseManager
from logger_config import setup_logger

logger = setup_logger(__name__)

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# æ¡†æ¶ç±»å‹å®šä¹‰
FrameworkType = Literal["langchain", "anthropic"]


class PRAnalysisRunnable:
    """PR åˆ†æçš„ Runnable åŒ…è£…å™¨ - æ”¯æŒå¤šç§æ¡†æ¶"""

    def __init__(
        self,
        framework: FrameworkType = "langchain",
        enable_tools: bool = True,
        check_exists: bool = True,
        vector_store: Optional[VectorStoreManager] = None,
    ):
        """
        åˆå§‹åŒ– PR åˆ†æå™¨

        Args:
            framework: åˆ†ææ¡†æ¶ ('langchain', 'anthropic')
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
            check_exists: æ˜¯å¦æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“
            vector_store: å‘é‡æ•°æ®åº“å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºæ£€æŸ¥ PR æ˜¯å¦å­˜åœ¨ï¼‰
        """
        self.framework = framework
        self.enable_tools = enable_tools
        self.check_exists = check_exists
        self.vector_store = vector_store

        logger.info(f"ğŸ”§ åˆå§‹åŒ– PR åˆ†æå™¨ (æ¡†æ¶: {framework})...")

        # æ ¹æ®æ¡†æ¶ç±»å‹åˆ›å»ºå¯¹åº”çš„ analyzer
        if framework == "langchain":
            self.analyzer = PRAnalysisLangChain()
        elif framework == "anthropic":
            self.analyzer = PRAnalysisAnthropic()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¡†æ¶: {framework}")

        logger.info(f"âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def __call__(self, inputs: Dict) -> Dict:
        """æ‰§è¡Œ PR åˆ†æï¼ˆåŒæ­¥è°ƒç”¨ï¼‰"""
        pr_number = inputs.get("pr_number")

        # å¦‚æœå¯ç”¨äº†æ£€æŸ¥ä¸”å‘é‡æ•°æ®åº“å¯ç”¨ï¼Œå…ˆæ£€æŸ¥ PR æ˜¯å¦å­˜åœ¨
        if self.check_exists and self.vector_store and pr_number:
            logger.info(f"ğŸ” æ£€æŸ¥ PR #{pr_number} æ˜¯å¦å·²åœ¨å‘é‡æ•°æ®åº“ä¸­...")
            if self.vector_store.pr_exists(pr_number):
                logger.info(f"âœ… PR #{pr_number} å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“ï¼Œè·³è¿‡åˆ†æ")
                return {
                    "success": True,
                    "pr_number": pr_number,
                    "pr_title": f"PR #{pr_number}",
                    "analysis": "",
                    "analyzed_at": "",
                    "skipped": True,
                    "skip_reason": "already_in_vector_db",
                }
            else:
                logger.info(f"âœ… PR #{pr_number} ä¸å­˜åœ¨ï¼Œç»§ç»­åˆ†æ")

        logger.info(f"ğŸ” æ­¥éª¤ 1: åˆ†æ PR #{pr_number if pr_number else '(æœ€æ–°)'}...")
        logger.info(f"   ä½¿ç”¨æ¡†æ¶: {self.framework}")
        logger.info(f"   å·¥å…·è°ƒç”¨: {'å¯ç”¨' if self.enable_tools else 'ç¦ç”¨'}")

        # å¯¹äºå¼‚æ­¥çš„ analyzerï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
        result = asyncio.run(
            self.analyzer.analyze_pr(
                pr_number=pr_number, enable_tools=self.enable_tools
            )
        )

        if result.get("success"):
            logger.info(f"âœ… PR åˆ†æå®Œæˆ")
        else:
            logger.error(f"âŒ PR åˆ†æå¤±è´¥: {result.get('error')}")

        result["skipped"] = False
        return result

    def close(self):
        """å…³é—­èµ„æº"""
        if self.analyzer:
            self.analyzer.close()


class VectorStoreRunnable:
    """å‘é‡æ•°æ®åº“å­˜å‚¨çš„ Runnable åŒ…è£…å™¨"""

    def __init__(self, vector_store: Optional[VectorStoreManager] = None):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“å­˜å‚¨å™¨

        Args:
            vector_store: å‘é‡æ•°æ®åº“å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        logger.info("ğŸ”§ åˆå§‹åŒ–å‘é‡æ•°æ®åº“å­˜å‚¨å™¨...")
        self.vector_store = vector_store
        self.enabled = vector_store is not None

        if self.enabled:
            logger.info("âœ… å‘é‡æ•°æ®åº“å­˜å‚¨å·²å¯ç”¨")
        else:
            logger.warning("âš ï¸ å‘é‡æ•°æ®åº“æœªæä¾›ï¼Œå°†è·³è¿‡å­˜å‚¨æ­¥éª¤")

    def __call__(self, analysis_result: Dict) -> Dict:
        """ä¿å­˜åˆ†æç»“æœåˆ°å‘é‡æ•°æ®åº“"""
        # å¦‚æœåˆ†æè¢«è·³è¿‡æˆ–å¤±è´¥ï¼Œä¸ä¿å­˜
        if analysis_result.get("skipped"):
            analysis_result["vector_stored"] = False
            return analysis_result

        if not self.enabled or not analysis_result.get("success"):
            analysis_result["vector_stored"] = False
            return analysis_result

        logger.info(f"ğŸ’¾ æ­¥éª¤ 2: ä¿å­˜åˆ°å‘é‡æ•°æ®åº“...")

        try:
            pr_number = analysis_result["pr_number"]
            pr_title = analysis_result["pr_title"]
            analysis = analysis_result["analysis"]

            # æ„å»º metadata
            metadata = {
                "analyzed_at": analysis_result.get(
                    "analyzed_at", datetime.now().isoformat()
                ),
            }

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if self.vector_store.pr_exists(pr_number):
                logger.warning(f"âš ï¸ PR #{pr_number} å·²å­˜åœ¨ï¼Œæ›´æ–°è®°å½•...")
                self.vector_store.delete_pr_analysis(pr_number)

            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            success = self.vector_store.add_pr_analysis(
                pr_number=pr_number,
                pr_title=pr_title,
                analysis=analysis,
                metadata=metadata,
            )

            analysis_result["vector_stored"] = success

            if success:
                logger.info(f"âœ… å·²ä¿å­˜åˆ°å‘é‡æ•°æ®åº“")
            else:
                logger.warning(f"âš ï¸ å‘é‡æ•°æ®åº“ä¿å­˜å¤±è´¥")

        except Exception as e:
            logger.error(f"âŒ å‘é‡æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            analysis_result["vector_stored"] = False

        return analysis_result


def create_pr_analysis_chain(
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
    check_exists: bool = True,
):
    """
    åˆ›å»º PR åˆ†æ Chainï¼ˆä½¿ç”¨ LangChain LCEL è¯­æ³•ï¼‰

    Args:
        framework: åˆ†ææ¡†æ¶ ('langchain', 'anthropic')
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        check_exists: æ˜¯å¦åœ¨åˆ†æå‰æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“

    Returns:
        LangChain Runnable Chain

    ä½¿ç”¨æ–¹æ³•:
        # ä½¿ç”¨ LangChain
        chain = create_pr_analysis_chain(framework='langchain')
        result = chain.invoke({"pr_number": 15685})

        # ä½¿ç”¨ Anthropic API
        chain = create_pr_analysis_chain(framework='anthropic')
        result = chain.invoke({"pr_number": 15685})
    """
    logger.info("ğŸ”§ åˆ›å»º PR åˆ†æ Chain...")
    logger.info(f"   æ¡†æ¶: {framework}")
    logger.info(f"   å·¥å…·è°ƒç”¨: {'å¯ç”¨' if enable_tools else 'ç¦ç”¨'}")
    logger.info(f"   å‘é‡å­˜å‚¨: {'å¯ç”¨' if save_to_vector else 'ç¦ç”¨'}")
    logger.info(f"   æ£€æŸ¥å­˜åœ¨: {'å¯ç”¨' if check_exists else 'ç¦ç”¨'}")

    # ç»Ÿä¸€åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
    vector_store = None
    if save_to_vector or check_exists:
        logger.info("ğŸ”§ åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        try:
            vector_store = VectorStoreManager()
            logger.info("âœ… å‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âš ï¸ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            if save_to_vector:
                logger.warning("âš ï¸ å°†è·³è¿‡å‘é‡æ•°æ®åº“å­˜å‚¨æ­¥éª¤")
            if check_exists:
                logger.warning("âš ï¸ å°†ä¸æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨")
            vector_store = None

    # åˆ›å»º PR åˆ†æ Runnable
    analyze_runnable = PRAnalysisRunnable(
        framework=framework,
        enable_tools=enable_tools,
        check_exists=check_exists,
        vector_store=vector_store,
    )

    # å¦‚æœéœ€è¦å‘é‡å­˜å‚¨ï¼Œåˆ›å»ºå®Œæ•´é“¾
    if save_to_vector:
        vector_store_runnable = VectorStoreRunnable(vector_store=vector_store)

        # ä½¿ç”¨ LCEL ç®¡é“æ“ä½œç¬¦ç»„åˆé“¾
        # analyze -> vector_store
        chain = (
            RunnablePassthrough()
            | RunnableLambda(analyze_runnable)
            | RunnableLambda(vector_store_runnable)
        )
    else:
        # åªæœ‰åˆ†æï¼Œä¸ä¿å­˜åˆ°å‘é‡å­˜å‚¨
        chain = RunnablePassthrough() | RunnableLambda(analyze_runnable)

    return chain


def run_pr_analysis(
    pr_number: Optional[int] = None,
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
    check_exists: bool = True,
) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œ PR åˆ†æ Chain

    Args:
        pr_number: PR ç¼–å·ï¼Œå¦‚æœä¸º None åˆ™åˆ†ææœ€æ–° PR
        framework: åˆ†ææ¡†æ¶ ('langchain', 'anthropic')
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        check_exists: æ˜¯å¦åœ¨åˆ†æå‰æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“

    Returns:
        åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å« vector_stored å­—æ®µ

    ç¤ºä¾‹:
        # ä½¿ç”¨ LangChain
        result = run_pr_analysis(pr_number=15685, framework='langchain')

        # ä½¿ç”¨ Anthropic API
        result = run_pr_analysis(pr_number=15685, framework='anthropic')

        # ä½¿ç”¨ Anthropicï¼Œä¸å¯ç”¨å·¥å…·
        result = run_pr_analysis(pr_number=15685, framework='anthropic', enable_tools=False)

        # åªåˆ†æï¼Œä¸ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        result = run_pr_analysis(pr_number=15685, save_to_vector=False)
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ å¯åŠ¨ PR åˆ†æå·¥ä½œæµ")
    logger.info(f"{'='*80}")

    # åˆ›å»º Chain
    chain = create_pr_analysis_chain(
        framework=framework,
        enable_tools=enable_tools,
        save_to_vector=save_to_vector,
        check_exists=check_exists,
    )

    # è¿è¡Œ Chain
    result = chain.invoke({"pr_number": pr_number})

    logger.info(f"{'='*80}")
    logger.info(f"ğŸ‰ å·¥ä½œæµå®Œæˆ")
    logger.info(f"{'='*80}")

    return result


def get_prs_by_date_range(
    since_date: str,
    days: int = 7,
) -> List[int]:
    """
    ä»æ•°æ®åº“ä¸­è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…å·²åˆå¹¶çš„ PR ç¼–å·åˆ—è¡¨

    Args:
        since_date: èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ï¼Œå¿…éœ€
        days: å¤©æ•°èŒƒå›´ï¼Œé»˜è®¤ 7 å¤©

    Returns:
        PR ç¼–å·åˆ—è¡¨
    """
    db = DatabaseManager()

    try:
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        start_date = since_date
        end_date = (
            datetime.strptime(since_date, "%Y-%m-%d") + timedelta(days=days)
        ).strftime("%Y-%m-%d")

        # ä»æ•°æ®åº“æŸ¥è¯¢, [start_date, end_date)
        pr_numbers = db.get_merged_prs_in_range(start_date, end_date)

        logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(pr_numbers)} ä¸ªå·²åˆå¹¶çš„ PR")

        return pr_numbers

    finally:
        db.close()


def batch_analyze_prs(
    pr_numbers: List[int],
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
    check_exists: bool = True,
) -> Dict:
    """
    æ‰¹é‡åˆ†æå¤šä¸ª PR

    Args:
        pr_numbers: PR ç¼–å·åˆ—è¡¨
        framework: åˆ†ææ¡†æ¶
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        check_exists: æ˜¯å¦åœ¨åˆ†æå‰æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“

    Returns:
        åŒ…å«æˆåŠŸå’Œå¤±è´¥ç»Ÿè®¡çš„ç»“æœå­—å…¸
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ æ‰¹é‡åˆ†æ {len(pr_numbers)} ä¸ª PR")
    logger.info(f"{'='*80}")

    results = {
        "total": len(pr_numbers),
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "failed_prs": [],
        "skipped_prs": [],
    }

    # åˆ›å»ºä¸€ä¸ª Chain å¯¹è±¡
    chain = create_pr_analysis_chain(
        framework=framework,
        enable_tools=enable_tools,
        save_to_vector=save_to_vector,
        check_exists=check_exists,
    )

    for i, pr_number in enumerate(pr_numbers, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"è¿›åº¦: {i}/{len(pr_numbers)} - PR #{pr_number}")
        logger.info(f"{'='*80}")

        try:
            # ä½¿ç”¨å¤ç”¨çš„ chain å¯¹è±¡
            result = chain.invoke({"pr_number": pr_number})

            if result.get("skipped"):
                results["skipped"] += 1
                results["skipped_prs"].append(pr_number)
                logger.info(f"â­ï¸ PR #{pr_number} å·²è·³è¿‡")
            elif result.get("success"):
                results["success"] += 1
                logger.info(f"âœ… PR #{pr_number} åˆ†ææˆåŠŸ")
            else:
                results["failed"] += 1
                results["failed_prs"].append(pr_number)
                logger.error(f"âŒ PR #{pr_number} åˆ†æå¤±è´¥")

        except Exception as e:
            results["failed"] += 1
            results["failed_prs"].append(pr_number)
            logger.error(f"âŒ PR #{pr_number} å¤„ç†å¼‚å¸¸: {e}")

    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆ")
    logger.info(f"{'='*80}")
    logger.info(f"æ€»è®¡: {results['total']}")
    logger.info(f"æˆåŠŸ: {results['success']}")
    logger.info(f"è·³è¿‡: {results['skipped']}")
    logger.info(f"å¤±è´¥: {results['failed']}")
    if results["skipped_prs"]:
        logger.info(f"è·³è¿‡çš„PR: {results['skipped_prs']}")
    if results["failed_prs"]:
        logger.warning(f"å¤±è´¥çš„PR: {results['failed_prs']}")
    logger.info(f"{'='*80}")

    return results


# ä¸»æ–¹æ³•
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="PR åˆ†æ + å‘é‡æ•°æ®åº“å­˜å‚¨å·¥å…· (æ”¯æŒæ‰¹é‡å¤„ç†)"
    )

    # æ—¥æœŸèŒƒå›´å‚æ•°
    parser.add_argument(
        "--since_date",
        type=str,
        help="èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ï¼Œç”¨äºæ‰¹é‡å¤„ç†æ—¶å¿…éœ€",
    )
    parser.add_argument(
        "--days",
        type=int,
        default=7,
        help="ä»èµ·å§‹æ—¥æœŸå¼€å§‹çš„å¤©æ•°èŒƒå›´ (é»˜è®¤: 7)",
    )

    # PR ç¼–å·å‚æ•°ï¼ˆå•ä¸ª PRï¼‰
    parser.add_argument(
        "--pr_number",
        type=int,
        help="å•ä¸ª PR ç¼–å·ï¼ˆä¸æ—¥æœŸèŒƒå›´å‚æ•°äº’æ–¥ï¼‰",
    )

    # æ¡†æ¶é€‰æ‹©
    parser.add_argument(
        "--framework",
        type=str,
        choices=["langchain", "anthropic"],
        default="langchain",
        help="åˆ†ææ¡†æ¶ (é»˜è®¤: langchain)",
    )

    # å·¥å…·å’Œå­˜å‚¨é€‰é¡¹
    parser.add_argument(
        "--no_tools",
        action="store_true",
        help="ç¦ç”¨å·¥å…·è°ƒç”¨",
    )
    parser.add_argument(
        "--no_vector",
        action="store_true",
        help="ä¸ä¿å­˜åˆ°å‘é‡æ•°æ®åº“",
    )
    parser.add_argument(
        "--no_check_exists",
        action="store_true",
        help="ä¸æ£€æŸ¥ PR æ˜¯å¦å·²å­˜åœ¨ï¼ˆå¼ºåˆ¶é‡æ–°åˆ†æï¼‰",
    )

    args = parser.parse_args()

    logger.info("ğŸš€ PR åˆ†æ + å‘é‡æ•°æ®åº“å­˜å‚¨å·¥å…·")
    logger.info("ä½¿ç”¨ LangChain LCEL: analyze | vector_store")
    logger.info("æ”¯æŒå¤šç§æ¡†æ¶: langchain, anthropic")
    logger.info("=" * 80)

    enable_tools = not args.no_tools
    save_to_vector = not args.no_vector
    check_exists = not args.no_check_exists

    # åˆ¤æ–­æ˜¯å•ä¸ª PR è¿˜æ˜¯æ‰¹é‡å¤„ç†
    if args.pr_number:
        # å•ä¸ª PR æ¨¡å¼
        if args.since_date:
            logger.error("âŒ é”™è¯¯: --pr_number ä¸èƒ½ä¸ --since_date åŒæ—¶ä½¿ç”¨")
            exit(1)

        result = run_pr_analysis(
            pr_number=args.pr_number,
            framework=args.framework,
            enable_tools=enable_tools,
            save_to_vector=save_to_vector,
            check_exists=check_exists,
        )

        # æ‰“å°ç»“æœæ‘˜è¦
        logger.info(f"\nğŸ“‹ ç»“æœæ‘˜è¦:")
        logger.info(f"  PR ç¼–å·: {result.get('pr_number')}")
        logger.info(f"  PR æ ‡é¢˜: {result.get('pr_title')}")
        logger.info(f"  åˆ†ææˆåŠŸ: {result.get('success')}")
        logger.info(f"  å·²è·³è¿‡: {result.get('skipped', False)}")
        logger.info(f"  å‘é‡å­˜å‚¨: {result.get('vector_stored', False)}")

        if result.get("success") and not result.get("skipped"):
            logger.info(f"\nğŸ“„ åˆ†æå†…å®¹é¢„è§ˆ:")
            analysis = result.get("analysis", "")
            preview = analysis[:500] + "..." if len(analysis) > 500 else analysis
            logger.info(preview)

    elif args.since_date:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        pr_numbers = get_prs_by_date_range(
            since_date=args.since_date,
            days=args.days,
        )

        if not pr_numbers:
            logger.warning("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ PR")
            exit(0)

        results = batch_analyze_prs(
            pr_numbers=pr_numbers,
            framework=args.framework,
            enable_tools=enable_tools,
            save_to_vector=save_to_vector,
            check_exists=check_exists,
        )

    else:
        logger.error("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --pr_number æˆ– --since_date")
        parser.print_help()
        exit(1)
