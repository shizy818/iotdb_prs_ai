#!/usr/bin/env python3
"""
ä½¿ç”¨ LangChain LCEL (LangChain Expression Language)
å°† PR åˆ†æå’Œå‘é‡æ•°æ®åº“å­˜å‚¨ä¸²è”èµ·æ¥

ä½¿ç”¨ç®¡é“æ“ä½œç¬¦: analyze_pr | save_to_vector_store
æ”¯æŒå¤šç§æ¡†æ¶: langchain, claude_agent_sdk, anthropic
"""
import os
import asyncio
import argparse
from datetime import datetime, timedelta
from typing import Dict, Optional, Literal, List

from langchain_core.runnables import RunnableLambda, RunnablePassthrough

from pr_analysis_langchain import PRAnalysisLangChain
from pr_analysis_cc_sdk import PRAnalysisClaudeAgentSDK
from pr_analysis_anthropic import PRAnalysisAnthropic
from vector_store import VectorStoreManager
from database import DatabaseManager

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# æ¡†æ¶ç±»å‹å®šä¹‰
FrameworkType = Literal["langchain", "claude_agent_sdk", "anthropic"]


class PRAnalysisRunnable:
    """PR åˆ†æçš„ Runnable åŒ…è£…å™¨ - æ”¯æŒå¤šç§æ¡†æ¶"""

    def __init__(
        self, framework: FrameworkType = "langchain", enable_tools: bool = True
    ):
        """
        åˆå§‹åŒ– PR åˆ†æå™¨

        Args:
            framework: åˆ†ææ¡†æ¶ ('langchain', 'claude_agent_sdk', 'anthropic')
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
        """
        self.framework = framework
        self.enable_tools = enable_tools

        print(f"ğŸ”§ åˆå§‹åŒ– PR åˆ†æå™¨ (æ¡†æ¶: {framework})...")

        # æ ¹æ®æ¡†æ¶ç±»å‹åˆ›å»ºå¯¹åº”çš„ analyzer
        if framework == "langchain":
            self.analyzer = PRAnalysisLangChain()
        elif framework == "claude_agent_sdk":
            self.analyzer = PRAnalysisClaudeAgentSDK()
        elif framework == "anthropic":
            self.analyzer = PRAnalysisAnthropic()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¡†æ¶: {framework}")

        print(f"âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ\n")

    def __call__(self, inputs: Dict) -> Dict:
        """æ‰§è¡Œ PR åˆ†æï¼ˆåŒæ­¥è°ƒç”¨ï¼‰"""
        pr_number = inputs.get("pr_number")
        print(f"\nğŸ” æ­¥éª¤ 1: åˆ†æ PR #{pr_number if pr_number else '(æœ€æ–°)'}...")
        print(f"   ä½¿ç”¨æ¡†æ¶: {self.framework}")
        print(f"   å·¥å…·è°ƒç”¨: {'å¯ç”¨' if self.enable_tools else 'ç¦ç”¨'}\n")

        # å¯¹äºå¼‚æ­¥çš„ analyzerï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
        result = asyncio.run(
            self.analyzer.analyze_pr(
                pr_number=pr_number, enable_tools=self.enable_tools
            )
        )

        if result.get("success"):
            print(f"âœ… PR åˆ†æå®Œæˆ\n")
        else:
            print(f"âŒ PR åˆ†æå¤±è´¥: {result.get('error')}\n")

        return result

    def close(self):
        """å…³é—­èµ„æº"""
        if self.analyzer:
            self.analyzer.close()


class VectorStoreRunnable:
    """å‘é‡æ•°æ®åº“å­˜å‚¨çš„ Runnable åŒ…è£…å™¨"""

    def __init__(self):
        print("ğŸ”§ åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        try:
            self.vector_store = VectorStoreManager()
            self.enabled = True
            print("âœ… å‘é‡æ•°æ®åº“å·²å¯ç”¨\n")
        except Exception as e:
            print(f"âš ï¸ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†è·³è¿‡å‘é‡æ•°æ®åº“å­˜å‚¨æ­¥éª¤\n")
            self.vector_store = None
            self.enabled = False

    def __call__(self, analysis_result: Dict) -> Dict:
        """ä¿å­˜åˆ†æç»“æœåˆ°å‘é‡æ•°æ®åº“"""
        if not self.enabled or not analysis_result.get("success"):
            analysis_result["vector_stored"] = False
            return analysis_result

        print(f"ğŸ’¾ æ­¥éª¤ 2: ä¿å­˜åˆ°å‘é‡æ•°æ®åº“...")

        try:
            pr_number = analysis_result["pr_number"]
            pr_title = analysis_result["pr_title"]
            analysis = analysis_result["analysis"]

            # æ„å»º metadata
            metadata = {
                "analyzed_at": analysis_result.get(
                    "analyzed_at", datetime.now().isoformat()
                ),
            }

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if self.vector_store.pr_exists(pr_number):
                print(f"âš ï¸ PR #{pr_number} å·²å­˜åœ¨ï¼Œæ›´æ–°è®°å½•...")
                self.vector_store.delete_pr_analysis(pr_number)

            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            success = self.vector_store.add_pr_analysis(
                pr_number=pr_number,
                pr_title=pr_title,
                analysis=analysis,
                metadata=metadata,
            )

            analysis_result["vector_stored"] = success

            if success:
                print(f"âœ… å·²ä¿å­˜åˆ°å‘é‡æ•°æ®åº“\n")
            else:
                print(f"âš ï¸ å‘é‡æ•°æ®åº“ä¿å­˜å¤±è´¥\n")

        except Exception as e:
            print(f"âŒ å‘é‡æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}\n")
            import traceback

            traceback.print_exc()
            analysis_result["vector_stored"] = False

        return analysis_result


def create_pr_analysis_chain(
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
):
    """
    åˆ›å»º PR åˆ†æ Chainï¼ˆä½¿ç”¨ LangChain LCEL è¯­æ³•ï¼‰

    Args:
        framework: åˆ†ææ¡†æ¶ ('langchain', 'claude_agent_sdk', 'anthropic')
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“

    Returns:
        LangChain Runnable Chain

    ä½¿ç”¨æ–¹æ³•:
        # ä½¿ç”¨ LangChain
        chain = create_pr_analysis_chain(framework='langchain')
        result = chain.invoke({"pr_number": 15685})

        # ä½¿ç”¨ Anthropic API
        chain = create_pr_analysis_chain(framework='anthropic')
        result = chain.invoke({"pr_number": 15685})

        # ä½¿ç”¨ Claude Agent SDK
        chain = create_pr_analysis_chain(framework='claude_agent_sdk')
        result = chain.invoke({"pr_number": 15685})
    """
    print("ğŸ”§ åˆ›å»º PR åˆ†æ Chain...")
    print(f"   æ¡†æ¶: {framework}")
    print(f"   å·¥å…·è°ƒç”¨: {'å¯ç”¨' if enable_tools else 'ç¦ç”¨'}")
    print(f"   å‘é‡å­˜å‚¨: {'å¯ç”¨' if save_to_vector else 'ç¦ç”¨'}")
    print()

    # åˆ›å»º PR åˆ†æ Runnable
    analyze_runnable = PRAnalysisRunnable(
        framework=framework, enable_tools=enable_tools
    )

    # å¦‚æœéœ€è¦å‘é‡å­˜å‚¨ï¼Œåˆ›å»ºå®Œæ•´é“¾
    if save_to_vector:
        vector_store_runnable = VectorStoreRunnable()

        # ä½¿ç”¨ LCEL ç®¡é“æ“ä½œç¬¦ç»„åˆé“¾
        # analyze -> vector_store
        chain = (
            RunnablePassthrough()
            | RunnableLambda(analyze_runnable)
            | RunnableLambda(vector_store_runnable)
        )
    else:
        # åªæœ‰åˆ†æï¼Œä¸ä¿å­˜åˆ°å‘é‡å­˜å‚¨
        chain = RunnablePassthrough() | RunnableLambda(analyze_runnable)

    return chain


def run_pr_analysis(
    pr_number: Optional[int] = None,
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œ PR åˆ†æ Chain

    Args:
        pr_number: PR ç¼–å·ï¼Œå¦‚æœä¸º None åˆ™åˆ†ææœ€æ–° PR
        framework: åˆ†ææ¡†æ¶ ('langchain', 'claude_agent_sdk', 'anthropic')
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“

    Returns:
        åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å« vector_stored å­—æ®µ

    ç¤ºä¾‹:
        # ä½¿ç”¨ LangChain
        result = run_pr_analysis(pr_number=15685, framework='langchain')

        # ä½¿ç”¨ Anthropic API
        result = run_pr_analysis(pr_number=15685, framework='anthropic')

        # ä½¿ç”¨ Claude Agent SDKï¼Œä¸å¯ç”¨å·¥å…·
        result = run_pr_analysis(pr_number=15685, framework='claude_agent_sdk', enable_tools=False)

        # åªåˆ†æï¼Œä¸ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        result = run_pr_analysis(pr_number=15685, save_to_vector=False)
    """
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¯åŠ¨ PR åˆ†æå·¥ä½œæµ")
    print(f"{'='*80}\n")

    # åˆ›å»º Chain
    chain = create_pr_analysis_chain(
        framework=framework, enable_tools=enable_tools, save_to_vector=save_to_vector
    )

    # è¿è¡Œ Chain
    result = chain.invoke({"pr_number": pr_number})

    print(f"{'='*80}")
    print(f"ğŸ‰ å·¥ä½œæµå®Œæˆ")
    print(f"{'='*80}\n")

    return result


def get_prs_by_date_range(
    since_date: str,
    days: int = 7,
) -> List[int]:
    """
    ä»æ•°æ®åº“ä¸­è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…å·²åˆå¹¶çš„ PR ç¼–å·åˆ—è¡¨

    Args:
        since_date: èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ï¼Œå¿…éœ€
        days: å¤©æ•°èŒƒå›´ï¼Œé»˜è®¤ 7 å¤©

    Returns:
        PR ç¼–å·åˆ—è¡¨
    """
    db = DatabaseManager()

    try:
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        start_date = since_date
        end_date = (
            datetime.strptime(since_date, "%Y-%m-%d") + timedelta(days=days)
        ).strftime("%Y-%m-%d")

        # ä»æ•°æ®åº“æŸ¥è¯¢, [start_date, end_date)
        pr_numbers = db.get_merged_prs_in_range(start_date, end_date)

        print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"ğŸ“Š æ‰¾åˆ° {len(pr_numbers)} ä¸ªå·²åˆå¹¶çš„ PR\n")

        return pr_numbers

    finally:
        db.close()


def batch_analyze_prs(
    pr_numbers: List[int],
    framework: FrameworkType = "langchain",
    enable_tools: bool = True,
    save_to_vector: bool = True,
) -> Dict:
    """
    æ‰¹é‡åˆ†æå¤šä¸ª PR

    Args:
        pr_numbers: PR ç¼–å·åˆ—è¡¨
        framework: åˆ†ææ¡†æ¶
        enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
        save_to_vector: æ˜¯å¦ä¿å­˜åˆ°å‘é‡æ•°æ®åº“

    Returns:
        åŒ…å«æˆåŠŸå’Œå¤±è´¥ç»Ÿè®¡çš„ç»“æœå­—å…¸
    """
    print(f"\n{'='*80}")
    print(f"ğŸš€ æ‰¹é‡åˆ†æ {len(pr_numbers)} ä¸ª PR")
    print(f"{'='*80}\n")

    results = {
        "total": len(pr_numbers),
        "success": 0,
        "failed": 0,
        "failed_prs": [],
    }

    # åˆ›å»ºä¸€ä¸ª Chain å¯¹è±¡ï¼Œå¤ç”¨äºæ‰€æœ‰ PR
    print(f"ğŸ”§ åˆ›å»º PR åˆ†æ Chain...")
    print(f"   æ¡†æ¶: {framework}")
    print(f"   å·¥å…·è°ƒç”¨: {'å¯ç”¨' if enable_tools else 'ç¦ç”¨'}")
    print(f"   å‘é‡å­˜å‚¨: {'å¯ç”¨' if save_to_vector else 'ç¦ç”¨'}")
    print()

    chain = create_pr_analysis_chain(
        framework=framework, enable_tools=enable_tools, save_to_vector=save_to_vector
    )

    for i, pr_number in enumerate(pr_numbers, 1):
        print(f"\n{'='*80}")
        print(f"è¿›åº¦: {i}/{len(pr_numbers)} - PR #{pr_number}")
        print(f"{'='*80}\n")

        try:
            # ä½¿ç”¨å¤ç”¨çš„ chain å¯¹è±¡
            result = chain.invoke({"pr_number": pr_number})

            if result.get("success"):
                results["success"] += 1
                print(f"âœ… PR #{pr_number} åˆ†ææˆåŠŸ\n")
            else:
                results["failed"] += 1
                results["failed_prs"].append(pr_number)
                print(f"âŒ PR #{pr_number} åˆ†æå¤±è´¥\n")

        except Exception as e:
            results["failed"] += 1
            results["failed_prs"].append(pr_number)
            print(f"âŒ PR #{pr_number} å¤„ç†å¼‚å¸¸: {e}\n")

    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆ")
    print(f"{'='*80}")
    print(f"æ€»è®¡: {results['total']}")
    print(f"æˆåŠŸ: {results['success']}")
    print(f"å¤±è´¥: {results['failed']}")
    if results["failed_prs"]:
        print(f"å¤±è´¥çš„PR: {results['failed_prs']}")
    print(f"{'='*80}\n")

    return results


# ä¸»æ–¹æ³•
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="PR åˆ†æ + å‘é‡æ•°æ®åº“å­˜å‚¨å·¥å…· (æ”¯æŒæ‰¹é‡å¤„ç†)"
    )

    # æ—¥æœŸèŒƒå›´å‚æ•°
    parser.add_argument(
        "--since_date",
        type=str,
        help="èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ï¼Œç”¨äºæ‰¹é‡å¤„ç†æ—¶å¿…éœ€",
    )
    parser.add_argument(
        "--days",
        type=int,
        default=7,
        help="ä»èµ·å§‹æ—¥æœŸå¼€å§‹çš„å¤©æ•°èŒƒå›´ (é»˜è®¤: 7)",
    )

    # PR ç¼–å·å‚æ•°ï¼ˆå•ä¸ª PRï¼‰
    parser.add_argument(
        "--pr_number",
        type=int,
        help="å•ä¸ª PR ç¼–å·ï¼ˆä¸æ—¥æœŸèŒƒå›´å‚æ•°äº’æ–¥ï¼‰",
    )

    # æ¡†æ¶é€‰æ‹©
    parser.add_argument(
        "--framework",
        type=str,
        choices=["langchain", "claude_agent_sdk", "anthropic"],
        default="claude_agent_sdk",
        help="åˆ†ææ¡†æ¶ (é»˜è®¤: claude_agent_sdk)",
    )

    # å·¥å…·å’Œå­˜å‚¨é€‰é¡¹
    parser.add_argument(
        "--no_tools",
        action="store_true",
        help="ç¦ç”¨å·¥å…·è°ƒç”¨",
    )
    parser.add_argument(
        "--no_vector",
        action="store_true",
        help="ä¸ä¿å­˜åˆ°å‘é‡æ•°æ®åº“",
    )

    args = parser.parse_args()

    print("ğŸš€ PR åˆ†æ + å‘é‡æ•°æ®åº“å­˜å‚¨å·¥å…·")
    print("ä½¿ç”¨ LangChain LCEL: analyze | vector_store")
    print("æ”¯æŒå¤šç§æ¡†æ¶: langchain, claude_agent_sdk, anthropic")
    print("=" * 80)
    print()

    enable_tools = not args.no_tools
    save_to_vector = not args.no_vector

    # åˆ¤æ–­æ˜¯å•ä¸ª PR è¿˜æ˜¯æ‰¹é‡å¤„ç†
    if args.pr_number:
        # å•ä¸ª PR æ¨¡å¼
        if args.since_date:
            print("âŒ é”™è¯¯: --pr_number ä¸èƒ½ä¸ --since_date åŒæ—¶ä½¿ç”¨")
            exit(1)

        result = run_pr_analysis(
            pr_number=args.pr_number,
            framework=args.framework,
            enable_tools=enable_tools,
            save_to_vector=save_to_vector,
        )

        # æ‰“å°ç»“æœæ‘˜è¦
        print(f"\nğŸ“‹ ç»“æœæ‘˜è¦:")
        print(f"  PR ç¼–å·: {result.get('pr_number')}")
        print(f"  PR æ ‡é¢˜: {result.get('pr_title')}")
        print(f"  åˆ†ææˆåŠŸ: {result.get('success')}")
        print(f"  å‘é‡å­˜å‚¨: {result.get('vector_stored', False)}")

        if result.get("success"):
            print(f"\nğŸ“„ åˆ†æå†…å®¹é¢„è§ˆ:")
            analysis = result.get("analysis", "")
            preview = analysis[:500] + "..." if len(analysis) > 500 else analysis
            print(preview)

    elif args.since_date:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        pr_numbers = get_prs_by_date_range(
            since_date=args.since_date,
            days=args.days,
        )

        if not pr_numbers:
            print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ PR")
            exit(0)

        results = batch_analyze_prs(
            pr_numbers=pr_numbers,
            framework=args.framework,
            enable_tools=enable_tools,
            save_to_vector=save_to_vector,
        )

    else:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --pr_number æˆ– --since_date")
        parser.print_help()
        exit(1)
