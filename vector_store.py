#!/usr/bin/env python3
"""
å‘é‡æ•°æ®åº“ç®¡ç†æ¨¡å— - ä½¿ç”¨Chromaå­˜å‚¨PRåˆ†æç»“æœ
æ”¯æŒå‘é‡åŒ–å­˜å‚¨ã€è¯­ä¹‰æ£€ç´¢å’Œç›¸ä¼¼åº¦æœç´¢
"""

import os
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document
from logger_config import setup_logger

logger = setup_logger(__name__)


class VectorStoreManager:
    """ç®¡ç†PRåˆ†æç»“æœçš„å‘é‡æ•°æ®åº“"""

    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨

        Args:
            persist_directory: Chromaæ•°æ®åº“æŒä¹…åŒ–ç›®å½•
        """
        self.persist_directory = persist_directory

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(persist_directory, exist_ok=True)

        # åˆå§‹åŒ–embeddingæ¨¡å‹ - ä½¿ç”¨è½»é‡çº§çš„ä¸­æ–‡æ¨¡å‹
        logger.info("æ­£åœ¨åŠ è½½embeddingæ¨¡å‹...")
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆvector_store.pyæ‰€åœ¨ç›®å½•ï¼‰
        project_root = Path(__file__).parent
        model_path = project_root / "models" / "paraphrase-multilingual-MiniLM-L12-v2"

        if not model_path.exists():
            raise FileNotFoundError(
                f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\n" f"è¯·ç¡®ä¿æ¨¡å‹å·²ä¸‹è½½åˆ°æ­£ç¡®ä½ç½®"
            )

        self.embeddings = HuggingFaceEmbeddings(
            model_name=str(model_path),
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )

        # åˆå§‹åŒ–æˆ–åŠ è½½Chromaå‘é‡æ•°æ®åº“
        self.vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings,
            collection_name="pr_analysis",
        )

        logger.info(f"å‘é‡æ•°æ®åº“å·²åˆå§‹åŒ–: {persist_directory}")

    def pr_exists(self, pr_number: int) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šPRæ˜¯å¦å·²ç»å­˜åœ¨äºå‘é‡æ•°æ®åº“ä¸­

        Args:
            pr_number: PRç¼–å·

        Returns:
            å¦‚æœPRå·²å­˜åœ¨è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            # æŸ¥è¯¢æŒ‡å®špr_numberçš„æ–‡æ¡£
            results = self.vectorstore.get(where={"pr_number": pr_number})
            # å¦‚æœæœ‰ç»“æœï¼Œè¯´æ˜PRå·²å­˜åœ¨
            return len(results.get("ids", [])) > 0
        except Exception as e:
            logger.warning(f"æ£€æŸ¥PRæ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False

    def add_pr_analysis(
        self,
        pr_number: int,
        pr_title: str,
        analysis: str,
        metadata: Optional[Dict] = None,
        skip_if_exists: bool = True,
    ) -> bool:
        """
        æ·»åŠ PRåˆ†æç»“æœåˆ°å‘é‡æ•°æ®åº“

        Args:
            pr_number: PRç¼–å·
            pr_title: PRæ ‡é¢˜
            analysis: Claudeåˆ†æç»“æœ
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå¦‚åˆ†ææ—¶é—´ã€æ ‡ç­¾ç­‰ï¼‰
            skip_if_exists: å¦‚æœPRå·²å­˜åœ¨ï¼Œæ˜¯å¦è·³è¿‡æ·»åŠ ï¼ˆé»˜è®¤Trueï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            # æ£€æŸ¥PRæ˜¯å¦å·²å­˜åœ¨
            if skip_if_exists and self.pr_exists(pr_number):
                logger.info(f"PR #{pr_number} å·²å­˜åœ¨äºå‘é‡æ•°æ®åº“ä¸­ï¼Œè·³è¿‡æ·»åŠ ")
                return False

            # å‡†å¤‡æ–‡æ¡£å…ƒæ•°æ®
            doc_metadata = {
                "pr_number": pr_number,
                "pr_title": pr_title,
                "analyzed_at": datetime.now().isoformat(),
                "source": "claude_analysis",
            }

            # åˆå¹¶ç”¨æˆ·æä¾›çš„é¢å¤–å…ƒæ•°æ®
            if metadata:
                doc_metadata.update(metadata)

            # åˆ›å»ºå®Œæ•´çš„æ–‡æ¡£å†…å®¹ï¼ŒåŒ…å«PRåŸºæœ¬ä¿¡æ¯
            content = f"PR #{pr_number}: {pr_title}\n\n{analysis}"

            # åˆ›å»ºå•ä¸ªDocumentå¯¹è±¡
            doc = Document(page_content=content, metadata=doc_metadata)

            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            self.vectorstore.add_documents([doc])
            logger.info(f"PR #{pr_number} åˆ†æç»“æœå·²æ·»åŠ åˆ°å‘é‡æ•°æ®åº“")

            return True

        except Exception as e:
            logger.error(f"æ·»åŠ PRåˆ†æåˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def search_similar_prs(
        self, query: str, k: int = 5, filter_dict: Optional[Dict] = None
    ) -> List[Dict]:
        """
        è¯­ä¹‰æœç´¢ç›¸ä¼¼çš„PRåˆ†æ

        Args:
            query: æœç´¢æŸ¥è¯¢
            k: è¿”å›æœ€ç›¸ä¼¼çš„kä¸ªç»“æœ
            filter_dict: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶

        Returns:
            ç›¸ä¼¼PRåˆ—è¡¨ï¼ŒåŒ…å«å†…å®¹å’Œå…ƒæ•°æ®
        """
        try:
            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            if filter_dict:
                results = self.vectorstore.similarity_search(
                    query, k=k, filter=filter_dict
                )
            else:
                results = self.vectorstore.similarity_search(query, k=k)

            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for doc in results:
                formatted_results.append(
                    {
                        "pr_number": doc.metadata.get("pr_number"),
                        "pr_title": doc.metadata.get("pr_title"),
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                    }
                )

            return formatted_results

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    def search_with_score(
        self, query: str, k: int = 5, filter_dict: Optional[Dict] = None
    ) -> List[tuple]:
        """
        å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            k: è¿”å›æœ€ç›¸ä¼¼çš„kä¸ªç»“æœ
            filter_dict: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶

        Returns:
            (Document, score)å…ƒç»„åˆ—è¡¨
        """
        try:
            if filter_dict:
                results = self.vectorstore.similarity_search_with_score(
                    query, k=k, filter=filter_dict
                )
            else:
                results = self.vectorstore.similarity_search_with_score(query, k=k)

            return results

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    def get_pr_by_number(self, pr_number: int) -> Optional[Dict]:
        """
        æ ¹æ®PRç¼–å·è·å–åˆ†æç»“æœ

        Args:
            pr_number: PRç¼–å·

        Returns:
            åŒ…å«PRåˆ†æå†…å®¹å’Œå…ƒæ•°æ®çš„å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            # æŸ¥è¯¢æŒ‡å®špr_numberçš„æ‰€æœ‰æ–‡æ¡£
            results = self.vectorstore.get(where={"pr_number": pr_number})

            if not results or not results.get("ids"):
                return None

            # åˆå¹¶æ‰€æœ‰chunksçš„å†…å®¹
            documents = results.get("documents", [])
            metadatas = results.get("metadatas", [])

            if not documents:
                return None

            # ç»„åˆå®Œæ•´å†…å®¹
            full_content = "\n".join(documents)

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®ä½œä¸ºåŸºç¡€
            metadata = metadatas[0] if metadatas else {}

            return {
                "pr_number": pr_number,
                "pr_title": metadata.get("pr_title", ""),
                "content": full_content,
                "metadata": metadata,
            }

        except Exception as e:
            logger.error(f"è·å–PR #{pr_number}å¤±è´¥: {e}")
            return None

    def delete_pr_analysis(self, pr_number: int) -> bool:
        """
        åˆ é™¤æŒ‡å®šPRçš„åˆ†æç»“æœ

        Args:
            pr_number: PRç¼–å·

        Returns:
            æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        try:
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤åˆ é™¤
            self.vectorstore.delete(where={"pr_number": pr_number})
            logger.info(f"PR #{pr_number} çš„åˆ†æç»“æœå·²ä»å‘é‡æ•°æ®åº“åˆ é™¤")
            return True

        except Exception as e:
            logger.error(f"åˆ é™¤å¤±è´¥: {e}")
            return False

    def get_collection_stats(self) -> Dict:
        """
        è·å–å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            collection = self.vectorstore._collection
            count = collection.count()

            return {
                "total_documents": count,
                "collection_name": "pr_analysis",
                "persist_directory": self.persist_directory,
            }

        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    vector_store = VectorStoreManager()

    # æ·»åŠ ç¤ºä¾‹PRåˆ†æ
    sample_analysis = """
    è¿™æ˜¯ä¸€ä¸ªä¿®å¤JDBCé…ç½®é”™è¯¯çš„PRã€‚
    ä¸»è¦è§£å†³äº†feature.xmlè·¯å¾„é…ç½®é”™è¯¯çš„é—®é¢˜ã€‚
    å½±å“èŒƒå›´ï¼šä½¿ç”¨Karaféƒ¨ç½²çš„ç”¨æˆ·ã€‚
    å»ºè®®ä¼˜å…ˆçº§ï¼šä¸­ç­‰ã€‚
    """

    vector_store.add_pr_analysis(
        pr_number=16487,
        pr_title="Fix jdbc feature.xml error",
        analysis=sample_analysis,
        metadata={"labels": ["bug", "jdbc"]},
    )

    # æœç´¢ç¤ºä¾‹
    results = vector_store.search_similar_prs("JDBCé…ç½®é—®é¢˜", k=3)
    logger.info("\nğŸ” æœç´¢ç»“æœ:")
    for result in results:
        logger.info(f"PR #{result['pr_number']}: {result['pr_title']}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = vector_store.get_collection_stats()
    logger.info(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {stats}")
