#!/usr/bin/env python3
"""
PRåˆ†ææœç´¢å·¥å…·
ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œå¿«é€Ÿæ‰¾åˆ°ç›¸å…³çš„PRåˆ†æç»“æœ
"""

import argparse
import sys
from typing import List, Dict
from vector_store import VectorStoreManager


def format_search_result(result: Dict, index: int, show_full: bool = False) -> str:
    """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
    output = []
    output.append(f"\n{'='*80}")
    output.append(f"ç»“æœ #{index}")
    output.append(f"{'='*80}")
    output.append(f"PRç¼–å·: #{result['pr_number']}")
    output.append(f"PRæ ‡é¢˜: {result['pr_title']}")

    # æ˜¾ç¤ºå…ƒæ•°æ®
    metadata = result.get("metadata", {})
    if metadata.get("analyzed_at"):
        output.append(f"åˆ†ææ—¶é—´: {metadata['analyzed_at']}")
    if metadata.get("chunk_index") is not None:
        output.append(
            f"æ–‡æ¡£å—: {metadata['chunk_index'] + 1}/{metadata.get('total_chunks', '?')}"
        )

    output.append(f"\n{'å†…å®¹ç‰‡æ®µ':^80}")
    output.append("-" * 80)

    # æ˜¾ç¤ºå†…å®¹
    content = result["content"]
    if show_full:
        output.append(content)
    else:
        # åªæ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
        preview = content[:500]
        if len(content) > 500:
            preview += "\n...(æ›´å¤šå†…å®¹)"
        output.append(preview)

    return "\n".join(output)


def format_search_result_with_score(
    doc, score: float, index: int, show_full: bool = False
) -> str:
    """æ ¼å¼åŒ–å¸¦åˆ†æ•°çš„æœç´¢ç»“æœ"""
    output = []
    output.append(f"\n{'='*80}")
    output.append(f"ç»“æœ #{index} - ç›¸ä¼¼åº¦: {score:.4f}")
    output.append(f"{'='*80}")
    output.append(f"PRç¼–å·: #{doc.metadata.get('pr_number')}")
    output.append(f"PRæ ‡é¢˜: {doc.metadata.get('pr_title')}")

    # æ˜¾ç¤ºå…ƒæ•°æ®
    if doc.metadata.get("analyzed_at"):
        output.append(f"åˆ†ææ—¶é—´: {doc.metadata['analyzed_at']}")
    if doc.metadata.get("chunk_index") is not None:
        output.append(
            f"æ–‡æ¡£å—: {doc.metadata['chunk_index'] + 1}/{doc.metadata.get('total_chunks', '?')}"
        )

    output.append(f"\n{'å†…å®¹ç‰‡æ®µ':^80}")
    output.append("-" * 80)

    # æ˜¾ç¤ºå†…å®¹
    content = doc.page_content
    if show_full:
        output.append(content)
    else:
        # åªæ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
        preview = content[:500]
        if len(content) > 500:
            preview += "\n...(æ›´å¤šå†…å®¹)"
        output.append(preview)

    return "\n".join(output)


def search_command(args):
    """æ‰§è¡Œæœç´¢å‘½ä»¤"""
    print(f"\nğŸ” æœç´¢æŸ¥è¯¢: {args.query}")
    print(f"ğŸ“Š è¿”å›ç»“æœæ•°: {args.top_k}")

    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    vector_store = VectorStoreManager()

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = vector_store.get_collection_stats()
    print(f"ğŸ“š æ•°æ®åº“åŒ…å« {stats.get('total_documents', 0)} ä¸ªæ–‡æ¡£")

    # æ‰§è¡Œæœç´¢
    if args.with_score:
        print("\næ­£åœ¨æ‰§è¡Œè¯­ä¹‰æœç´¢ï¼ˆå¸¦ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰...")
        results = vector_store.search_with_score(args.query, k=args.top_k)

        if results:
            print(f"\næ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
            for idx, (doc, score) in enumerate(results, 1):
                print(format_search_result_with_score(doc, score, idx, args.full))
        else:
            print("\næœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
    else:
        print("\næ­£åœ¨æ‰§è¡Œè¯­ä¹‰æœç´¢...")
        results = vector_store.search_similar_prs(args.query, k=args.top_k)

        if results:
            print(f"\næ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
            for idx, result in enumerate(results, 1):
                print(format_search_result(result, idx, args.full))
        else:
            print("\næœªæ‰¾åˆ°ç›¸å…³ç»“æœ")


def fetch_command(args):
    """æ ¹æ®PRç¼–å·è·å–åˆ†æç»“æœ"""
    pr_number = args.pr_number
    print(f"\nğŸ” è·å–PR #{pr_number}çš„åˆ†æç»“æœ...")

    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    vector_store = VectorStoreManager()

    # è·å–ç‰¹å®šPR
    result = vector_store.get_pr_by_number(pr_number)

    if not result:
        print(f"\nâŒ æœªæ‰¾åˆ°PR #{pr_number}çš„åˆ†æç»“æœ")
        print("ğŸ’¡ æç¤º: è¯¥PRå¯èƒ½å°šæœªè¢«åˆ†æï¼Œè¯·å…ˆä½¿ç”¨analyze_pr.pyè¿›è¡Œåˆ†æ")
        return

    print(f"\nâœ… æ‰¾åˆ°PR #{pr_number}çš„åˆ†æç»“æœ")
    print("=" * 80)
    print(f"PRç¼–å·: #{result['pr_number']}")
    print(f"PRæ ‡é¢˜: {result['pr_title']}")

    metadata = result.get("metadata", {})
    if metadata.get("analyzed_at"):
        print(f"åˆ†ææ—¶é—´: {metadata['analyzed_at']}")

    print("=" * 80)
    print("\nåˆ†æå†…å®¹:\n")
    print(result["content"])
    print("\n" + "=" * 80)


def stats_command(args):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)

    vector_store = VectorStoreManager()
    stats = vector_store.get_collection_stats()

    print(f"é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
    print(f"æ€»æ–‡æ¡£æ•°: {stats.get('total_documents', 0)}")
    print(f"å­˜å‚¨è·¯å¾„: {stats.get('persist_directory', 'N/A')}")
    print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="PRåˆ†ææœç´¢å·¥å…· - ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æœç´¢JDBCç›¸å…³é—®é¢˜
  python search_pr_analysis.py search "JDBCé…ç½®é—®é¢˜"

  # æœç´¢å¹¶æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•°
  python search_pr_analysis.py search "Mavenæ„å»ºé”™è¯¯" --with-score

  # è¿”å›æ›´å¤šç»“æœ
  python search_pr_analysis.py search "Karaféƒ¨ç½²" --top-k 10

  # æ˜¾ç¤ºå®Œæ•´å†…å®¹
  python search_pr_analysis.py search "feature.xml" --full

  # è·å–æŒ‡å®šPRçš„åˆ†æç»“æœ
  python search_pr_analysis.py fetch 16487

  # æŸ¥çœ‹æ•°æ®åº“ç»Ÿè®¡
  python search_pr_analysis.py stats
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser("search", help="æœç´¢PRåˆ†æ")
    search_parser.add_argument("query", type=str, help="æœç´¢æŸ¥è¯¢")
    search_parser.add_argument(
        "--top-k", type=int, default=5, help="è¿”å›çš„ç»“æœæ•°é‡ (é»˜è®¤: 5)"
    )
    search_parser.add_argument(
        "--with-score", action="store_true", help="æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•°"
    )
    search_parser.add_argument("--full", action="store_true", help="æ˜¾ç¤ºå®Œæ•´å†…å®¹")

    # è·å–PRå‘½ä»¤
    fetch_parser = subparsers.add_parser("fetch", help="è·å–æŒ‡å®šPRçš„åˆ†æç»“æœ")
    fetch_parser.add_argument("pr_number", type=int, help="PRç¼–å·")

    # ç»Ÿè®¡å‘½ä»¤
    subparsers.add_parser("stats", help="æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")

    args = parser.parse_args()

    # æ‰§è¡Œå‘½ä»¤
    try:
        if args.command == "search":
            search_command(args)
        elif args.command == "fetch":
            fetch_command(args)
        elif args.command == "stats":
            stats_command(args)
        else:
            parser.print_help()
            return 1

        return 0

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
