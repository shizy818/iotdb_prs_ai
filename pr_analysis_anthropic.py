import asyncio
import json
import subprocess
from pathlib import Path
from typing import Dict, Optional, List

import anthropic
from database import DatabaseManager
from config import ANTHROPIC_BASE_URL, ANTHROPIC_API_KEY, DEFAULT_IOTDB_SOURCE_DIR

from pr_analysis_common import (
    build_analysis_query,
    get_pr_by_number,
)


def get_tool_definitions() -> List[Dict]:
    """
    è·å–å·¥å…·å®šä¹‰ï¼ˆAnthropic API æ ¼å¼ï¼‰
    """
    return [
        {
            "name": "read",
            "description": "è¯»å– IoTDB æºç æ–‡ä»¶çš„å†…å®¹ã€‚æ–‡ä»¶è·¯å¾„ç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ã€‚",
            "input_schema": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¦‚ 'iotdb-core/datanode/src/main/java/org/apache/iotdb/db/queryengine/execution/operator/process/TableIntoOperator.java'ï¼‰",
                    }
                },
                "required": ["file_path"],
            },
        },
        {
            "name": "glob",
            "description": "ä½¿ç”¨ glob æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶ã€‚æ”¯æŒ ** é€šé…ç¬¦ã€‚",
            "input_schema": {
                "type": "object",
                "properties": {
                    "pattern": {
                        "type": "string",
                        "description": "Glob æ¨¡å¼ï¼ˆå¦‚ '**/*TableIntoOperator*.java', '**/*.xml'ï¼‰",
                    },
                    "path": {
                        "type": "string",
                        "description": "æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•ï¼‰",
                    },
                },
                "required": ["pattern"],
            },
        },
        {
            "name": "grep",
            "description": "åœ¨ IoTDB æºç ä¸­æœç´¢åŒ¹é…çš„å†…å®¹ã€‚ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ã€‚",
            "input_schema": {
                "type": "object",
                "properties": {
                    "pattern": {
                        "type": "string",
                        "description": "æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰",
                    },
                    "path": {
                        "type": "string",
                        "description": "æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼‰",
                    },
                    "file_type": {
                        "type": "string",
                        "description": "æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ 'java', 'py', 'xml'ï¼‰ï¼ˆå¯é€‰ï¼‰",
                    },
                },
                "required": ["pattern"],
            },
        },
        {
            "name": "bash",
            "description": "æ‰§è¡Œå®‰å…¨çš„ git å‘½ä»¤ï¼ˆåªå…è®¸åªè¯»å‘½ä»¤å’Œ checkoutï¼‰ã€‚åœ¨ IoTDB æºç ç›®å½•ä¸­æ‰§è¡Œã€‚",
            "input_schema": {
                "type": "object",
                "properties": {
                    "command": {
                        "type": "string",
                        "description": "è¦æ‰§è¡Œçš„ git å‘½ä»¤ï¼ˆå¦‚ 'git checkout <commit_sha>', 'git status', 'git log'ï¼‰",
                    }
                },
                "required": ["command"],
            },
        },
    ]


class PRAnalysisAnthropic:
    def __init__(self, iotdb_source_dir: str = DEFAULT_IOTDB_SOURCE_DIR):
        """
        åˆå§‹åŒ–PRåˆ†æå™¨ï¼Œä½¿ç”¨Anthropic APIå’Œæ•°æ®åº“è¿æ¥

        Args:
            iotdb_source_dir: IoTDB æºç ç›®å½•è·¯å¾„
        """
        self.iotdb_source_dir = Path(iotdb_source_dir)
        self.db = DatabaseManager()

    def _execute_read_tool(self, file_path: str) -> Dict:
        """
        æ‰§è¡Œ read å·¥å…·ï¼šè¯»å–æ–‡ä»¶å†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            full_path = self.iotdb_source_dir / file_path
            if not full_path.exists():
                return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}

            # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆé™åˆ¶å¤§å°ï¼‰
            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read(500000)  # é™åˆ¶ 500KB

            return {"success": True, "content": content, "file_path": file_path}
        except Exception as e:
            return {"success": False, "error": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"}

    def _execute_glob_tool(self, pattern: str, path: str = "") -> Dict:
        """
        æ‰§è¡Œ glob å·¥å…·ï¼šæŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶

        Args:
            pattern: glob æ¨¡å¼ï¼ˆå¦‚ "**/*.java"ï¼‰
            path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            search_dir = self.iotdb_source_dir / path if path else self.iotdb_source_dir
            matches = list(search_dir.glob(pattern))

            # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
            relative_paths = [
                str(p.relative_to(self.iotdb_source_dir)) for p in matches[:100]
            ]  # é™åˆ¶ 100 ä¸ªç»“æœ

            return {
                "success": True,
                "matches": relative_paths,
                "count": len(relative_paths),
            }
        except Exception as e:
            return {"success": False, "error": f"Glob æœç´¢å¤±è´¥: {str(e)}"}

    def _execute_grep_tool(
        self, pattern: str, path: str = "", file_type: str = ""
    ) -> Dict:
        """
        æ‰§è¡Œ grep å·¥å…·ï¼šæœç´¢æ–‡ä»¶å†…å®¹

        Args:
            pattern: æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
            path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰
            file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ "java", "py"ï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            search_dir = self.iotdb_source_dir / path if path else self.iotdb_source_dir

            # æ„å»º rg (ripgrep) å‘½ä»¤
            cmd = ["rg", "--json", pattern, str(search_dir)]
            if file_type:
                cmd.extend(["--type", file_type])

            # æ‰§è¡Œæœç´¢
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)

            # è§£æç»“æœ
            matches = []
            for line in result.stdout.strip().split("\n"):
                if not line:
                    continue
                try:
                    data = json.loads(line)
                    if data.get("type") == "match":
                        match_data = data.get("data", {})
                        file_path = match_data.get("path", {}).get("text", "")
                        line_number = match_data.get("line_number")
                        line_text = match_data.get("lines", {}).get("text", "").strip()

                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                        if file_path:
                            rel_path = str(
                                Path(file_path).relative_to(self.iotdb_source_dir)
                            )
                            matches.append(
                                {
                                    "file": rel_path,
                                    "line": line_number,
                                    "content": line_text,
                                }
                            )
                except json.JSONDecodeError:
                    continue

            return {
                "success": True,
                "matches": matches[:50],  # é™åˆ¶ 50 ä¸ªç»“æœ
                "count": len(matches),
            }
        except FileNotFoundError:
            return {
                "success": False,
                "error": "ripgrep (rg) æœªå®‰è£…ï¼Œè¯·å®‰è£…: brew install ripgrep",
            }
        except Exception as e:
            return {"success": False, "error": f"Grep æœç´¢å¤±è´¥: {str(e)}"}

    def _execute_bash_tool(self, command: str) -> Dict:
        """
        æ‰§è¡Œ bash å·¥å…·ï¼šåªå…è®¸å®‰å…¨çš„ git å‘½ä»¤

        Args:
            command: è¦æ‰§è¡Œçš„å‘½ä»¤

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            # è§£æå‘½ä»¤
            cmd_parts = command.strip().split()
            if not cmd_parts:
                return {"success": False, "error": "å‘½ä»¤ä¸ºç©º"}

            first_cmd = cmd_parts[0].lower()

            # åªå…è®¸ git å‘½ä»¤
            if first_cmd != "git":
                return {
                    "success": False,
                    "error": f"åªå…è®¸ git å‘½ä»¤ï¼Œä¸å…è®¸: {first_cmd}",
                }

            if len(cmd_parts) < 2:
                return {"success": False, "error": "Git å‘½ä»¤ä¸å®Œæ•´"}

            git_subcmd = cmd_parts[1].lower()

            # å…è®¸çš„å®‰å…¨ git å‘½ä»¤ï¼ˆåªè¯» + checkoutï¼‰
            safe_git_commands = {
                "checkout",
                "status",
                "log",
                "show",
                "diff",
                "branch",
                "rev-parse",
                "ls-tree",
                "ls-files",
            }

            # å±é™©å‘½ä»¤é»‘åå•
            dangerous_git_commands = {
                "push",
                "reset",
                "clean",
                "rm",
                "commit",
                "rebase",
                "merge",
                "pull",
                "fetch",
                "add",
            }

            if git_subcmd in dangerous_git_commands:
                return {
                    "success": False,
                    "error": f"ç¦æ­¢æ‰§è¡Œå±é™©çš„ git å‘½ä»¤: git {git_subcmd}",
                }

            if git_subcmd not in safe_git_commands:
                return {
                    "success": False,
                    "error": f"Git å‘½ä»¤ '{git_subcmd}' ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼ˆå…è®¸: {', '.join(sorted(safe_git_commands))}ï¼‰",
                }

            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd_parts,
                cwd=str(self.iotdb_source_dir),
                capture_output=True,
                text=True,
                timeout=30,
            )

            # åˆå¹¶ stdout å’Œ stderr
            output = result.stdout
            if result.stderr:
                output += "\n" + result.stderr

            return {
                "success": result.returncode == 0,
                "output": output.strip(),
                "returncode": result.returncode,
            }

        except subprocess.TimeoutExpired:
            return {"success": False, "error": "å‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰"}
        except Exception as e:
            return {"success": False, "error": f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"}

    def _execute_tool(self, tool_name: str, tool_input: Dict) -> Dict:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨

        Args:
            tool_name: å·¥å…·åç§°
            tool_input: å·¥å…·è¾“å…¥å‚æ•°

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if tool_name == "read":
            return self._execute_read_tool(tool_input.get("file_path", ""))
        elif tool_name == "glob":
            return self._execute_glob_tool(
                tool_input.get("pattern", ""), tool_input.get("path", "") or ""
            )
        elif tool_name == "grep":
            return self._execute_grep_tool(
                tool_input.get("pattern", ""),
                tool_input.get("path", "") or "",
                tool_input.get("file_type", "") or "",
            )
        elif tool_name == "bash":
            return self._execute_bash_tool(tool_input.get("command", ""))
        else:
            return {"success": False, "error": f"æœªçŸ¥å·¥å…·: {tool_name}"}

    def get_pr_by_number(self, pr_number: Optional[int] = None) -> Optional[Dict]:
        """
        ä»æ•°æ®åº“è·å–æŒ‡å®šPRçš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šç¼–å·åˆ™è·å–æœ€æ–°çš„PR
        """
        return get_pr_by_number(pr_number, self.db)

    async def analyze_pr(
        self,
        pr_number: Optional[int] = None,
        max_tokens: int = 16384,
        temperature: float = 0.3,
        enable_tools: bool = True,
        max_tool_rounds: int = 10,
        use_cache: bool = True,
    ) -> Dict:
        """
        ä½¿ç”¨ Anthropic API è¿›è¡Œ PR åˆ†æï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼šread, glob, grep + cache_controlï¼‰

        Args:
            pr_number: PRç¼–å·
            max_tokens: æœ€å¤§è¾“å‡º tokensï¼ˆé»˜è®¤ 16384ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§ï¼ˆ0-1ï¼Œé»˜è®¤ 0.3ï¼Œè¶Šä½è¶Šä¸€è‡´ï¼‰
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰ï¼ˆé»˜è®¤ Trueï¼‰
            max_tool_rounds: æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°ï¼ˆé»˜è®¤ 10ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ prompt cachingï¼ˆé»˜è®¤ Trueï¼‰
        """
        # è·å–PRæ•°æ®
        target_pr = self.get_pr_by_number(pr_number)

        if not target_pr:
            if pr_number:
                return {"success": False, "error": f"æœªæ‰¾åˆ°ç¼–å·ä¸º {pr_number} çš„PR"}
            else:
                return {"success": False, "error": "æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°PRæ•°æ®"}

        pr_number = target_pr["number"]
        print(f"ğŸ” æ­£åœ¨åˆ†æ PR #{pr_number}: {target_pr['title']}")

        try:
            # åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯
            client = anthropic.Anthropic(
                base_url=ANTHROPIC_BASE_URL, api_key=ANTHROPIC_API_KEY
            )

            # è·å– diff å†…å®¹
            diff_content = target_pr.get("diff_content", "")
            diff_size = len(diff_content) if diff_content else 0
            print(f"ğŸ“¦ Diff å¤§å°: {diff_size:,} å­—ç¬¦ (~{diff_size // 4:,} tokens)")

            # æ„å»ºå®Œæ•´æŸ¥è¯¢
            query = build_analysis_query(target_pr, diff_content)
            query_size = len(query)
            print(f"ğŸ“Š å®Œæ•´æŸ¥è¯¢å¤§å°: {query_size:,} å­—ç¬¦ (~{query_size // 4:,} tokens)")

            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = "æ‚¨æ˜¯ä¸€åæ—¶åºæ•°æ®åº“IoTDBä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„PRä¿¡æ¯å’Œæœ¬åœ°iotdbæºç è¿›è¡Œåˆ†æï¼Œç„¶åæä¾›è¯¦ç»†çš„åˆ†æç»“æœã€‚"
            if enable_tools:
                system_prompt += """

**é‡è¦ï¼šåœ¨åˆ†æä¹‹å‰ï¼Œè¯·åŠ¡å¿…æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š**
1. ä½¿ç”¨ bash å·¥å…·æ‰§è¡Œ git checkout å‘½ä»¤ï¼Œå°†IoTDBæºç åˆ‡æ¢åˆ° PR çš„ merge_commitï¼ˆæŸ¥è¯¢ä¸­ä¼šæä¾›è¯¥ commit SHAï¼‰
   - ä¾‹å¦‚ï¼šbash å·¥å…·æ‰§è¡Œ `git checkout <merge_commit_sha>`
2. ä½¿ç”¨ glob å·¥å…·æŸ¥æ‰¾ diff ä¸­æ¶‰åŠçš„æºç æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼š`**/ClassName.java`ï¼‰
3. ä½¿ç”¨ read å·¥å…·è¯»å–è¿™äº›å®Œæ•´çš„æºç æ–‡ä»¶
4. ä½¿ç”¨ grep å·¥å…·æœç´¢ç›¸å…³çš„ç±»ã€æ–¹æ³•æˆ–å…³é”®å­—ä»¥è·å–æ›´å¤šä¸Šä¸‹æ–‡

æ³¨æ„ï¼šbash å·¥å…·åªå…è®¸æ‰§è¡Œå®‰å…¨çš„ git å‘½ä»¤ï¼ˆcheckout, status, log, show, diff ç­‰ï¼‰ï¼Œç¦æ­¢ä½¿ç”¨ pushã€resetã€clean ç­‰å±é™©å‘½ä»¤ã€‚"""

            print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨ Anthropic API å‘é€åˆ†æè¯·æ±‚...")
            print(f"   æ¨¡å‹: GLM-4.6")
            print(f"   æœ€å¤§è¾“å‡º tokens: {max_tokens:,}")
            print(f"   Temperature: {temperature}")
            print(
                f"   å·¥å…·æ”¯æŒ: {'å¯ç”¨ (read, glob, grep, bash)' if enable_tools else 'ç¦ç”¨'}"
            )
            print(f"   Prompt Caching: {'å¯ç”¨' if use_cache else 'ç¦ç”¨'}")

            # åˆå§‹åŒ–å¯¹è¯å†å²ï¼ˆå¦‚æœä½¿ç”¨ç¼“å­˜ï¼Œåœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸Šæ·»åŠ  cache_controlï¼‰
            if use_cache:
                system = [
                    {
                        "type": "text",
                        "text": system_prompt,
                        "cache_control": {"type": "ephemeral"},
                    }
                ]
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": query,
                                "cache_control": {"type": "ephemeral"},
                            }
                        ],
                    }
                ]
            else:
                system = [
                    {
                        "type": "text",
                        "text": system_prompt,
                    }
                ]
                messages = [
                    {
                        "role": "user",
                        "content": query,
                    }
                ]

            analysis_result = ""
            total_input_tokens = 0
            total_output_tokens = 0
            total_cache_creation_tokens = 0
            total_cache_read_tokens = 0
            tool_call_count = 0

            print(f"\n=== Claude åˆ†æç»“æœ ===\n")

            # å·¥å…·è°ƒç”¨å¾ªç¯
            for round_num in range(max_tool_rounds):
                stream_params = {
                    # "model": "claude-sonnet-4-5-20250929",
                    "model": "glm-4.6",
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "system": system,
                    "messages": messages,
                }

                # å¦‚æœå¯ç”¨å·¥å…·ï¼Œæ·»åŠ å·¥å…·å®šä¹‰
                if enable_tools:
                    stream_params["tools"] = get_tool_definitions()

                # å¦‚æœå¯ç”¨ç¼“å­˜ï¼Œæ·»åŠ å¿…è¦çš„ header
                if use_cache:
                    stream_params["extra_headers"] = {
                        "anthropic-beta": "prompt-caching-2024-07-31"
                    }

                # ä½¿ç”¨æµå¼ API
                with client.messages.stream(**stream_params) as stream:
                    # å®æ—¶æ‰“å°æµå¼è¾“å‡º
                    for text in stream.text_stream:
                        print(text, end="", flush=True)

                    # è·å–å®Œæ•´å“åº”
                    response = stream.get_final_message()

                    # æ›´æ–° token ç»Ÿè®¡
                    total_input_tokens += response.usage.input_tokens
                    total_output_tokens += response.usage.output_tokens

                    # æ›´æ–°ç¼“å­˜ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if hasattr(response.usage, "cache_creation_input_tokens"):
                        total_cache_creation_tokens += (
                            response.usage.cache_creation_input_tokens or 0
                        )
                    if hasattr(response.usage, "cache_read_input_tokens"):
                        total_cache_read_tokens += (
                            response.usage.cache_read_input_tokens or 0
                        )

                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    has_tool_use = any(
                        block.type == "tool_use" for block in response.content
                    )

                    if has_tool_use:
                        print()  # å·¥å…·è°ƒç”¨å‰æ¢è¡Œ
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        tool_results = []
                        for block in response.content:
                            if block.type == "tool_use":
                                tool_call_count += 1
                                tool_name = block.name
                                tool_input = block.input
                                tool_use_id = block.id

                                print(f"ğŸ”§ [å·¥å…·è°ƒç”¨ #{tool_call_count}] {tool_name}")

                                # æ‰“å°å·¥å…·å‚æ•°
                                if tool_name == "read":
                                    print(
                                        f"   ğŸ“„ è¯»å–æ–‡ä»¶: {tool_input.get('file_path', '')}"
                                    )
                                elif tool_name == "glob":
                                    print(
                                        f"   ğŸ“ æŸ¥æ‰¾æ–‡ä»¶: {tool_input.get('pattern', '')}"
                                    )
                                elif tool_name == "grep":
                                    print(
                                        f"   ğŸ” æœç´¢: {tool_input.get('pattern', '')}"
                                    )
                                elif tool_name == "bash":
                                    print(
                                        f"   ğŸŒ¿ Bash å‘½ä»¤: {tool_input.get('command', '')}"
                                    )

                                # æ‰§è¡Œå·¥å…·
                                tool_result = self._execute_tool(tool_name, tool_input)

                                # æ„å»ºå·¥å…·ç»“æœæ¶ˆæ¯
                                if tool_result.get("success"):
                                    # æˆåŠŸçš„ç»“æœ
                                    result_content = json.dumps(
                                        tool_result, ensure_ascii=False, indent=2
                                    )
                                else:
                                    # å¤±è´¥çš„ç»“æœ
                                    result_content = (
                                        f"é”™è¯¯: {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                                    )

                                tool_results.append(
                                    {
                                        "type": "tool_result",
                                        "tool_use_id": tool_use_id,
                                        "content": result_content,
                                    }
                                )

                                print(f"   âœ“ æ‰§è¡Œå®Œæˆ\n")

                        # å°† assistant çš„å“åº”æ·»åŠ åˆ°å†å²
                        messages.append(
                            {"role": "assistant", "content": response.content}
                        )

                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å†å²
                        messages.append({"role": "user", "content": tool_results})

                    else:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜åˆ†æå®Œæˆ
                        for block in response.content:
                            if hasattr(block, "text"):
                                analysis_result += block.text
                        break

            print(f"\n=== åˆ†æå®Œæˆ ===\n")

            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:")
            print(f"   è¾“å…¥ tokens: {total_input_tokens:,}")
            print(f"   è¾“å‡º tokens: {total_output_tokens:,}")

            if use_cache:
                print(f"   ç¼“å­˜åˆ›å»º tokens: {total_cache_creation_tokens:,}")
                print(f"   ç¼“å­˜è¯»å– tokens: {total_cache_read_tokens:,}")
                if total_cache_read_tokens > 0:
                    # ç¼“å­˜è¯»å–èŠ‚çœ 90% æˆæœ¬
                    cache_savings = total_cache_read_tokens * 0.9
                    print(f"   ğŸ’° ç¼“å­˜èŠ‚çœ: ~{cache_savings:,.0f} tokens æˆæœ¬")

            print(f"   æ€»è®¡ tokens: {total_input_tokens + total_output_tokens:,}")

            if enable_tools:
                print(f"   å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}")

            return {
                "success": True,
                "pr_number": pr_number,
                "analysis": analysis_result,
                "usage": {
                    "input_tokens": total_input_tokens,
                    "output_tokens": total_output_tokens,
                    "cache_creation_tokens": total_cache_creation_tokens,
                    "cache_read_tokens": total_cache_read_tokens,
                    "tool_calls": tool_call_count,
                },
            }

        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback

            traceback.print_exc()
            return {"success": False, "error": error_msg}

    def close(self):
        """
        å…³é—­æ•°æ®åº“è¿æ¥
        """
        if self.db:
            self.db.close()


async def main():
    """
    ä¸»å‡½æ•° - ä½¿ç”¨ Anthropic API è¿›è¡ŒPRåˆ†æ
    """
    analyzer = PRAnalysisAnthropic()

    try:
        print("ğŸš€ IoTDB PR åˆ†æå·¥å…· (Anthropic API)")
        print("=" * 60)

        # è·å– PR ç¼–å·
        pr_number = 13097

        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹PRåˆ†æ (ä½¿ç”¨ Anthropic API + å·¥å…·è°ƒç”¨ + Cache Control)...")

        result = await analyzer.analyze_pr(
            pr_number=pr_number,
            enable_tools=True,  # é»˜è®¤å¯ç”¨å·¥å…·
            use_cache=True,  # é»˜è®¤å¯ç”¨ç¼“å­˜
        )

        if result["success"]:
            print(f"\nâœ… åˆ†æå®Œæˆï¼")
            print(f"PR #{result['pr_number']}")

            # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
            usage = result.get("usage", {})
            print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
            print(f"   è¾“å…¥ tokens: {usage.get('input_tokens', 0):,}")
            print(f"   è¾“å‡º tokens: {usage.get('output_tokens', 0):,}")
            print(f"   ç¼“å­˜åˆ›å»º: {usage.get('cache_creation_tokens', 0):,}")
            print(f"   ç¼“å­˜è¯»å–: {usage.get('cache_read_tokens', 0):,}")
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥: {result['error']}")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except ValueError:
        print("\nâŒ PR ç¼–å·å¿…é¡»æ˜¯æ•°å­—")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
    finally:
        analyzer.close()


if __name__ == "__main__":
    asyncio.run(main())
