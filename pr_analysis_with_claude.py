import asyncio
import json
import os
from typing import Dict, Optional, List
from datetime import datetime
from pathlib import Path
import subprocess

from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions
import anthropic

from database import DatabaseManager


def build_analysis_query(pr_data: Dict, diff_content: str) -> str:
    """
    æ„å»ºå®Œæ•´çš„ä¸€æ¬¡æ€§PRåˆ†ææŸ¥è¯¢ï¼ˆç”¨äºå°å‹diffï¼‰

    Args:
        pr_data: PRæ•°æ®
        diff_content: å®Œæ•´çš„diffå†…å®¹
    """
    # æ„å»ºè¯„è®ºéƒ¨åˆ†
    if pr_data.get("comments"):
        comments_section = "- PR è®¨è®ºè¯„è®º\n"
        for idx, comment in enumerate(pr_data["comments"], 1):
            comment_time = comment.get("created_at", "")
            comment_user = comment.get("user", "æœªçŸ¥ç”¨æˆ·")
            comment_body = comment.get("body", "")
            comments_section += f"""  è¯„è®º {idx} (ä½œè€…: {comment_user}, æ—¶é—´: {comment_time}):
{comment_body}
---
"""
    else:
        comments_section = "- PR è®¨è®ºè¯„è®º: æ— \n"

    template = """
IoTDB PRè¯¦ç»†ä¿¡æ¯ï¼š
- ç¼–å·: {number}
- æ ‡é¢˜: {title}
- æè¿°: {body}
- åˆ›å»ºæ—¶é—´: {created_at}
- åˆå¹¶æ—¶é—´: {merged_at}
- ä½œè€…: {user}
- æ ‡ç­¾: {labels}
- ä»£ç å˜æ›´: +{additions} è¡Œ, -{deletions} è¡Œ
- åˆ†æ”¯: {head} -> {base}
- Diffé“¾æ¥: {diff_url}
{comments_section}

è¿™æ˜¯ä¸€ä¸ªIoTDBçš„Pull Requestï¼Œè¯·å…ˆé˜…è¯»ä¸Šè¿°åŸºæœ¬ä¿¡æ¯ã€‚æ¥ä¸‹æ¥æ˜¯ä»£ç å˜æ›´çš„diffå†…å®¹ï¼š

```diff
{diff_content}
```

ç°åœ¨ä½ å·²ç»æ”¶åˆ°äº†å®Œæ•´çš„PRä¿¡æ¯ï¼ˆåŒ…æ‹¬åŸºæœ¬ä¿¡æ¯å’Œdiffå†…å®¹ï¼‰ã€‚

**é‡è¦ï¼šåœ¨åˆ†æä¹‹å‰ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨ä»¥ä¸‹å·¥å…·è¯»å–ç›¸å…³æºç æ–‡ä»¶ä»¥ä¾¿æ·±å…¥ç†è§£ï¼š**
1. ä½¿ç”¨ Glob å·¥å…·æŸ¥æ‰¾ diff ä¸­æ¶‰åŠçš„æºç æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼š`**/ClassName.java`ï¼‰
2. ä½¿ç”¨ Read å·¥å…·è¯»å–è¿™äº›å®Œæ•´çš„æºç æ–‡ä»¶
3. ä½¿ç”¨ Grep å·¥å…·æœç´¢ç›¸å…³çš„ç±»ã€æ–¹æ³•æˆ–å…³é”®å­—ä»¥è·å–æ›´å¤šä¸Šä¸‹æ–‡

**ç„¶åè¿›è¡Œæ·±å…¥åˆ†æï¼š**
1. è¿™ä¸ªPRå…·ä½“è§£å†³äº†ä»€ä¹ˆæŠ€æœ¯é—®é¢˜ï¼Ÿ
2. å¦‚æœå®¢æˆ·ç¯å¢ƒæ²¡æœ‰è¿™ä¸ªä¿®å¤ï¼Œç³»ç»Ÿå¯èƒ½å‡ºç°ä»€ä¹ˆå…·ä½“é”™è¯¯ï¼Ÿ
3. å¯èƒ½å‡ºç°çš„é”™è¯¯ä¿¡æ¯ã€å¼‚å¸¸å †æ ˆæˆ–æ—¥å¿—æ˜¯ä»€ä¹ˆï¼Ÿ
4. å¯¹ç³»ç»Ÿç¨³å®šæ€§ã€æ€§èƒ½å’ŒåŠŸèƒ½çš„å½±å“ç¨‹åº¦ï¼Ÿ
5. å»ºè®®çš„ä¸´æ—¶è§£å†³æ–¹æ¡ˆæˆ–è§„é¿æªæ–½ï¼Ÿ
6. æ¨èçš„å‡çº§ä¼˜å…ˆçº§ï¼Ÿ

è¯·æä¾›è¯¦ç»†ã€ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚"""

    return template.format(
        number=pr_data.get("number", ""),
        title=pr_data.get("title", ""),
        body=pr_data.get("body", "æ— æè¿°"),
        created_at=pr_data.get("created_at", ""),
        merged_at=pr_data.get("merged_at", ""),
        user=pr_data.get("user", ""),
        labels=json.dumps(pr_data.get("labels", []), ensure_ascii=False),
        additions=pr_data.get("additions", 0),
        deletions=pr_data.get("deletions", 0),
        head=pr_data.get("head", ""),
        base=pr_data.get("base", ""),
        comments_section=comments_section,
        diff_url=pr_data.get("diff_url", "æ— "),
        diff_content=diff_content if diff_content else "æ— ä»£ç å˜æ›´",
    )


class PRAnalysisWithClaude:
    def __init__(
        self, iotdb_source_dir: str = "/Users/shizy/projects/iotdb_issues_ai/iotdb"
    ):
        """
        åˆå§‹åŒ–PRåˆ†æå™¨ï¼Œä½¿ç”¨ClaudeSDKClientå’Œæ•°æ®åº“è¿æ¥

        Args:
            iotdb_source_dir: IoTDB æºç ç›®å½•è·¯å¾„
        """
        self.db = DatabaseManager()
        self.iotdb_source_dir = Path(iotdb_source_dir)

        # è®¾ç½®Claude SDKç¯å¢ƒå˜é‡
        # os.environ["ANTHROPIC_BASE_URL"] = "https://open.bigmodel.cn/api/anthropic"
        # os.environ["ANTHROPIC_API_KEY"] = (
        #    "9be7a6c89bfc4cd99efb491c77140aa4.GI2bDndwSd7hqy69"
        # )
        os.environ["ANTHROPIC_BASE_URL"] = "https://claude.ihainan.me/api"
        os.environ["ANTHROPIC_API_KEY"] = (
            "cr_03077874a9a4ba5a5ff4135387c70f3614ed4e58b949df94e7b6f87282d44483"
        )

    def get_pr_by_number(self, pr_number: Optional[int] = None) -> Optional[Dict]:
        """
        ä»æ•°æ®åº“è·å–æŒ‡å®šPRçš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šç¼–å·åˆ™è·å–æœ€æ–°çš„PR
        """
        try:
            cursor = self.db.connection.cursor(dictionary=True)

            if pr_number:
                query = """
                SELECT number, title, body, created_at, merged_at, user, labels,
                       head, base, additions, deletions, diff_url, comments_url
                FROM iotdb_prs
                WHERE number = %s
                """
                cursor.execute(query, (pr_number,))
            else:
                query = """
                SELECT number, title, body, created_at, merged_at, user, labels,
                       head, base, additions, deletions, diff_url, comments_url
                FROM iotdb_prs
                ORDER BY merged_at DESC
                LIMIT 1
                """
                cursor.execute(query)

            pr = cursor.fetchone()

            if pr:
                # è§£æJSONæ ¼å¼çš„labels
                if pr["labels"]:
                    try:
                        pr["labels"] = json.loads(pr["labels"])
                    except (json.JSONDecodeError, TypeError):
                        pr["labels"] = []
                else:
                    pr["labels"] = []

                # è·å–å¯¹åº”çš„diffå†…å®¹
                diff_query = """
                SELECT diff_content
                FROM pr_diffs
                WHERE pr_number = %s
                ORDER BY created_at DESC
                LIMIT 1
                """
                cursor.execute(diff_query, (pr["number"],))
                diff_result = cursor.fetchone()

                if diff_result and diff_result["diff_content"]:
                    pr["diff_content"] = diff_result["diff_content"]
                else:
                    pr["diff_content"] = None

                # è·å–å¯¹åº”çš„è¯„è®ºå†…å®¹
                comments_query = """
                SELECT id, user, body, created_at, updated_at, html_url
                FROM pr_comments
                WHERE pr_number = %s
                ORDER BY created_at ASC
                """
                cursor.execute(comments_query, (pr["number"],))
                comments_results = cursor.fetchall()

                if comments_results:
                    pr["comments"] = comments_results
                else:
                    pr["comments"] = []

            cursor.close()
            return pr

        except Exception as e:
            print(f"ä»æ•°æ®åº“è·å–PRæ•°æ®æ—¶å‡ºé”™: {e}")
            return None

    def _execute_read_tool(self, file_path: str) -> Dict:
        """
        æ‰§è¡Œ read å·¥å…·ï¼šè¯»å–æ–‡ä»¶å†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            full_path = self.iotdb_source_dir / file_path
            if not full_path.exists():
                return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}

            # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆé™åˆ¶å¤§å°ï¼‰
            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read(500000)  # é™åˆ¶ 500KB

            return {"success": True, "content": content, "file_path": file_path}
        except Exception as e:
            return {"success": False, "error": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"}

    def _execute_glob_tool(self, pattern: str, path: str = "") -> Dict:
        """
        æ‰§è¡Œ glob å·¥å…·ï¼šæŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶

        Args:
            pattern: glob æ¨¡å¼ï¼ˆå¦‚ "**/*.java"ï¼‰
            path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            search_dir = self.iotdb_source_dir / path if path else self.iotdb_source_dir
            matches = list(search_dir.glob(pattern))

            # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
            relative_paths = [
                str(p.relative_to(self.iotdb_source_dir)) for p in matches[:100]
            ]  # é™åˆ¶ 100 ä¸ªç»“æœ

            return {
                "success": True,
                "matches": relative_paths,
                "count": len(relative_paths),
            }
        except Exception as e:
            return {"success": False, "error": f"Glob æœç´¢å¤±è´¥: {str(e)}"}

    def _execute_grep_tool(
        self, pattern: str, path: str = "", file_type: str = ""
    ) -> Dict:
        """
        æ‰§è¡Œ grep å·¥å…·ï¼šæœç´¢æ–‡ä»¶å†…å®¹

        Args:
            pattern: æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
            path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº iotdb_source_dirï¼‰
            file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ "java", "py"ï¼‰

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        try:
            search_dir = self.iotdb_source_dir / path if path else self.iotdb_source_dir

            # æ„å»º rg (ripgrep) å‘½ä»¤
            cmd = ["rg", "--json", pattern, str(search_dir)]
            if file_type:
                cmd.extend(["--type", file_type])

            # æ‰§è¡Œæœç´¢
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)

            # è§£æç»“æœ
            matches = []
            for line in result.stdout.strip().split("\n"):
                if not line:
                    continue
                try:
                    data = json.loads(line)
                    if data.get("type") == "match":
                        match_data = data.get("data", {})
                        file_path = match_data.get("path", {}).get("text", "")
                        line_number = match_data.get("line_number")
                        line_text = match_data.get("lines", {}).get("text", "").strip()

                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                        if file_path:
                            rel_path = str(
                                Path(file_path).relative_to(self.iotdb_source_dir)
                            )
                            matches.append(
                                {
                                    "file": rel_path,
                                    "line": line_number,
                                    "content": line_text,
                                }
                            )
                except json.JSONDecodeError:
                    continue

            return {
                "success": True,
                "matches": matches[:50],  # é™åˆ¶ 50 ä¸ªç»“æœ
                "count": len(matches),
            }
        except FileNotFoundError:
            # å¦‚æœæ²¡æœ‰ ripgrepï¼Œå›é€€åˆ° grep
            return {
                "success": False,
                "error": "ripgrep (rg) æœªå®‰è£…ï¼Œè¯·å®‰è£…: brew install ripgrep",
            }
        except Exception as e:
            return {"success": False, "error": f"Grep æœç´¢å¤±è´¥: {str(e)}"}

    def _get_tool_definitions(self) -> List[Dict]:
        """
        è·å–å·¥å…·å®šä¹‰ï¼ˆAnthropic API æ ¼å¼ï¼‰
        """
        return [
            {
                "name": "read",
                "description": "è¯»å– IoTDB æºç æ–‡ä»¶çš„å†…å®¹ã€‚æ–‡ä»¶è·¯å¾„ç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ã€‚",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¦‚ 'iotdb-core/datanode/src/main/java/org/apache/iotdb/db/queryengine/execution/operator/process/TableIntoOperator.java'ï¼‰",
                        }
                    },
                    "required": ["file_path"],
                },
            },
            {
                "name": "glob",
                "description": "ä½¿ç”¨ glob æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶ã€‚æ”¯æŒ ** é€šé…ç¬¦ã€‚",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "pattern": {
                            "type": "string",
                            "description": "Glob æ¨¡å¼ï¼ˆå¦‚ '**/*TableIntoOperator*.java', '**/*.xml'ï¼‰",
                        },
                        "path": {
                            "type": "string",
                            "description": "æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•ï¼‰",
                        },
                    },
                    "required": ["pattern"],
                },
            },
            {
                "name": "grep",
                "description": "åœ¨ IoTDB æºç ä¸­æœç´¢åŒ¹é…çš„å†…å®¹ã€‚ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ã€‚",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "pattern": {
                            "type": "string",
                            "description": "æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰",
                        },
                        "path": {
                            "type": "string",
                            "description": "æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼‰",
                        },
                        "file_type": {
                            "type": "string",
                            "description": "æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ 'java', 'py', 'xml'ï¼‰ï¼ˆå¯é€‰ï¼‰",
                        },
                    },
                    "required": ["pattern"],
                },
            },
        ]

    def _execute_tool(self, tool_name: str, tool_input: Dict) -> Dict:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨

        Args:
            tool_name: å·¥å…·åç§°
            tool_input: å·¥å…·è¾“å…¥å‚æ•°

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if tool_name == "read":
            return self._execute_read_tool(tool_input.get("file_path", ""))
        elif tool_name == "glob":
            return self._execute_glob_tool(
                tool_input.get("pattern", ""), tool_input.get("path", "")
            )
        elif tool_name == "grep":
            return self._execute_grep_tool(
                tool_input.get("pattern", ""),
                tool_input.get("path", ""),
                tool_input.get("file_type", ""),
            )
        else:
            return {"success": False, "error": f"æœªçŸ¥å·¥å…·: {tool_name}"}

    async def analyze_pr_with_anthropic(
        self,
        pr_number: Optional[int] = None,
        max_tokens: int = 16384,
        temperature: float = 0.3,
        enable_tools: bool = True,
        max_tool_rounds: int = 10,
        use_cache: bool = True,
    ) -> Dict:
        """
        ä½¿ç”¨ Anthropic API è¿›è¡Œ PR åˆ†æï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼šread, glob, grep + cache_controlï¼‰

        Args:
            pr_number: PRç¼–å·
            max_tokens: æœ€å¤§è¾“å‡º tokensï¼ˆé»˜è®¤ 16384ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§ï¼ˆ0-1ï¼Œé»˜è®¤ 0.3ï¼Œè¶Šä½è¶Šä¸€è‡´ï¼‰
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨ï¼ˆread, glob, grepï¼‰ï¼ˆé»˜è®¤ Trueï¼‰
            max_tool_rounds: æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°ï¼ˆé»˜è®¤ 10ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ prompt cachingï¼ˆé»˜è®¤ Trueï¼‰
        """
        # è·å–PRæ•°æ®
        target_pr = self.get_pr_by_number(pr_number)

        if not target_pr:
            if pr_number:
                return {"success": False, "error": f"æœªæ‰¾åˆ°ç¼–å·ä¸º {pr_number} çš„PR"}
            else:
                return {"success": False, "error": "æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°PRæ•°æ®"}

        pr_number = target_pr["number"]
        print(f"ğŸ” æ­£åœ¨åˆ†æ PR #{pr_number}: {target_pr['title']}")

        try:
            # åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯
            client = anthropic.Anthropic()

            # è·å– diff å†…å®¹
            diff_content = target_pr.get("diff_content", "")
            diff_size = len(diff_content) if diff_content else 0
            print(f"ğŸ“¦ Diff å¤§å°: {diff_size:,} å­—ç¬¦ (~{diff_size // 4:,} tokens)")

            # æ„å»ºå®Œæ•´æŸ¥è¯¢
            query = build_analysis_query(target_pr, diff_content)
            query_size = len(query)
            print(f"ğŸ“Š å®Œæ•´æŸ¥è¯¢å¤§å°: {query_size:,} å­—ç¬¦ (~{query_size // 4:,} tokens)")

            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = "æ‚¨æ˜¯ä¸€åæ—¶åºæ•°æ®åº“IoTDBä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„PRä¿¡æ¯å’Œæœ¬åœ°iotdbæºç è¿›è¡Œåˆ†æï¼Œç„¶åæä¾›è¯¦ç»†çš„åˆ†æç»“æœã€‚"
            if enable_tools:
                system_prompt += "\næ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è¯»å–å’Œæœç´¢ IoTDB æºç ï¼šreadï¼ˆè¯»å–æ–‡ä»¶ï¼‰ã€globï¼ˆæŸ¥æ‰¾æ–‡ä»¶ï¼‰ã€grepï¼ˆæœç´¢å†…å®¹ï¼‰ã€‚"

            print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨ Anthropic API å‘é€åˆ†æè¯·æ±‚...")
            print(f"   æ¨¡å‹: claude-sonnet-4-5-20250929")
            print(f"   æœ€å¤§è¾“å‡º tokens: {max_tokens:,}")
            print(f"   Temperature: {temperature}")
            print(
                f"   å·¥å…·æ”¯æŒ: {'å¯ç”¨ (read, glob, grep)' if enable_tools else 'ç¦ç”¨'}"
            )
            print(f"   Prompt Caching: {'å¯ç”¨' if use_cache else 'ç¦ç”¨'}")

            # åˆå§‹åŒ–å¯¹è¯å†å²ï¼ˆå¦‚æœä½¿ç”¨ç¼“å­˜ï¼Œåœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸Šæ·»åŠ  cache_controlï¼‰
            if use_cache:
                system = [
                    {
                        "type": "text",
                        "text": system_prompt,
                        "cache_control": {"type": "ephemeral"},
                    }
                ]
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": query,
                                "cache_control": {"type": "ephemeral"},
                            }
                        ],
                    }
                ]
            else:
                system = [
                    {
                        "type": "text",
                        "text": system_prompt,
                    }
                ]
                messages = [
                    {
                        "role": "user",
                        "content": query,
                    }
                ]

            analysis_result = ""
            total_input_tokens = 0
            total_output_tokens = 0
            total_cache_creation_tokens = 0
            total_cache_read_tokens = 0
            tool_call_count = 0

            print(f"\n=== Claude åˆ†æç»“æœ ===\n")

            # å·¥å…·è°ƒç”¨å¾ªç¯
            for round_num in range(max_tool_rounds):
                stream_params = {
                    "model": "claude-sonnet-4-5-20250929",
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "system": system,
                    "messages": messages,
                }

                # å¦‚æœå¯ç”¨å·¥å…·ï¼Œæ·»åŠ å·¥å…·å®šä¹‰
                if enable_tools:
                    stream_params["tools"] = self._get_tool_definitions()

                # å¦‚æœå¯ç”¨ç¼“å­˜ï¼Œæ·»åŠ å¿…è¦çš„ header
                if use_cache:
                    stream_params["extra_headers"] = {
                        "anthropic-beta": "prompt-caching-2024-07-31"
                    }

                # ä½¿ç”¨æµå¼ API
                with client.messages.stream(**stream_params) as stream:
                    # å®æ—¶æ‰“å°æµå¼è¾“å‡º
                    for text in stream.text_stream:
                        print(text, end="", flush=True)

                    # è·å–å®Œæ•´å“åº”
                    response = stream.get_final_message()

                    # æ›´æ–° token ç»Ÿè®¡
                    total_input_tokens += response.usage.input_tokens
                    total_output_tokens += response.usage.output_tokens

                    # æ›´æ–°ç¼“å­˜ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if hasattr(response.usage, "cache_creation_input_tokens"):
                        total_cache_creation_tokens += (
                            response.usage.cache_creation_input_tokens or 0
                        )
                    if hasattr(response.usage, "cache_read_input_tokens"):
                        total_cache_read_tokens += (
                            response.usage.cache_read_input_tokens or 0
                        )

                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    has_tool_use = any(
                        block.type == "tool_use" for block in response.content
                    )

                    if has_tool_use:
                        print()  # å·¥å…·è°ƒç”¨å‰æ¢è¡Œ
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        tool_results = []
                        for block in response.content:
                            if block.type == "tool_use":
                                tool_call_count += 1
                                tool_name = block.name
                                tool_input = block.input
                                tool_use_id = block.id

                                print(f"ğŸ”§ [å·¥å…·è°ƒç”¨ #{tool_call_count}] {tool_name}")

                                # æ‰“å°å·¥å…·å‚æ•°
                                if tool_name == "read":
                                    print(
                                        f"   ğŸ“„ è¯»å–æ–‡ä»¶: {tool_input.get('file_path', '')}"
                                    )
                                elif tool_name == "glob":
                                    print(
                                        f"   ğŸ“ æŸ¥æ‰¾æ–‡ä»¶: {tool_input.get('pattern', '')}"
                                    )
                                elif tool_name == "grep":
                                    print(
                                        f"   ğŸ” æœç´¢: {tool_input.get('pattern', '')}"
                                    )

                                # æ‰§è¡Œå·¥å…·
                                tool_result = self._execute_tool(tool_name, tool_input)

                                # æ„å»ºå·¥å…·ç»“æœæ¶ˆæ¯
                                if tool_result.get("success"):
                                    # æˆåŠŸçš„ç»“æœ
                                    result_content = json.dumps(
                                        tool_result, ensure_ascii=False, indent=2
                                    )
                                else:
                                    # å¤±è´¥çš„ç»“æœ
                                    result_content = (
                                        f"é”™è¯¯: {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                                    )

                                tool_results.append(
                                    {
                                        "type": "tool_result",
                                        "tool_use_id": tool_use_id,
                                        "content": result_content,
                                    }
                                )

                                print(f"   âœ“ æ‰§è¡Œå®Œæˆ\n")

                        # å°† assistant çš„å“åº”æ·»åŠ åˆ°å†å²
                        messages.append(
                            {"role": "assistant", "content": response.content}
                        )

                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å†å²
                        messages.append({"role": "user", "content": tool_results})

                    else:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜åˆ†æå®Œæˆ
                        for block in response.content:
                            if hasattr(block, "text"):
                                analysis_result += block.text
                        break

            print(f"\n\n=== åˆ†æå®Œæˆ ===\n")

            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:")
            print(f"   è¾“å…¥ tokens: {total_input_tokens:,}")
            print(f"   è¾“å‡º tokens: {total_output_tokens:,}")

            if use_cache:
                print(f"   ç¼“å­˜åˆ›å»º tokens: {total_cache_creation_tokens:,}")
                print(f"   ç¼“å­˜è¯»å– tokens: {total_cache_read_tokens:,}")
                if total_cache_read_tokens > 0:
                    # ç¼“å­˜è¯»å–èŠ‚çœ 90% æˆæœ¬
                    cache_savings = total_cache_read_tokens * 0.9
                    print(f"   ğŸ’° ç¼“å­˜èŠ‚çœ: ~{cache_savings:,.0f} tokens æˆæœ¬")

            print(f"   æ€»è®¡ tokens: {total_input_tokens + total_output_tokens:,}")

            if enable_tools:
                print(f"   å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}")

            return {
                "success": True,
                "pr_number": pr_number,
                "analysis": analysis_result,
                "usage": {
                    "input_tokens": total_input_tokens,
                    "output_tokens": total_output_tokens,
                    "cache_creation_tokens": total_cache_creation_tokens,
                    "cache_read_tokens": total_cache_read_tokens,
                    "tool_calls": tool_call_count,
                },
            }

        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback

            traceback.print_exc()
            return {"success": False, "error": error_msg}

    async def analyze_pr_with_cc_sdk(self, pr_number: Optional[int] = None) -> Dict:
        """
        åˆ†æå•ä¸ªPRï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šç¼–å·åˆ™åˆ†ææœ€æ–°çš„PR
        ä½¿ç”¨åˆ†æ‰¹ä¼ è¾“ç­–ç•¥ï¼šå…ˆå‘é€åŸºæœ¬ä¿¡æ¯ï¼Œå†åˆ†æ‰¹å‘é€diffå†…å®¹

        Args:
            pr_number: PRç¼–å·
        """
        # è·å–PRæ•°æ®
        target_pr = self.get_pr_by_number(pr_number)

        if not target_pr:
            if pr_number:
                return {"success": False, "error": f"æœªæ‰¾åˆ°ç¼–å·ä¸º {pr_number} çš„PR"}
            else:
                return {"success": False, "error": "æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°PRæ•°æ®"}

        pr_number = target_pr["number"]
        print(f"æ­£åœ¨åˆ†æ PR #{pr_number}: {target_pr['title']}")

        try:
            # è·å–diffå†…å®¹
            diff_content = target_pr.get("diff_content", "")
            diff_size = len(diff_content) if diff_content else 0

            # ä½¿ç”¨ClaudeSDKClientå‘é€æŸ¥è¯¢ï¼ˆclaude-agent-sdkï¼‰
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Claude Agent å®¢æˆ·ç«¯...")
            async with ClaudeSDKClient(
                options=ClaudeAgentOptions(
                    system_prompt="æ‚¨æ˜¯ä¸€åæ—¶åºæ•°æ®åº“IoTDBä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„PRä¿¡æ¯å’Œæœ¬åœ°iotdbæºç è¿›è¡Œåˆ†æï¼Œç„¶åæä¾›è¯¦ç»†çš„åˆ†æç»“æœã€‚",
                    max_turns=50,
                    cwd=self.iotdb_source_dir,  # IoTDB æºç ç›®å½•
                    allowed_tools=["read", "glob", "grep"],  # å…è®¸è¯»å–æ–‡ä»¶
                )
            ) as client:
                print("âœ“ å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                print(f"ğŸ“¦ Diffå¤§å°: {diff_size:,} å­—ç¬¦")

                # æ„å»ºå®Œæ•´æŸ¥è¯¢
                query = build_analysis_query(target_pr, diff_content)
                query_size = len(query)
                print(
                    f"ğŸ“Š å®Œæ•´æŸ¥è¯¢å¤§å°: {query_size:,} å­—ç¬¦ (~{query_size // 4:,} tokens)"
                )
                print("ğŸ“¤ æ­£åœ¨å‘é€å®Œæ•´çš„PRåˆ†æè¯·æ±‚...")

                await client.query(query)

                # æ”¶é›†åˆ†æç»“æœ
                analysis_result = ""
                tool_calls = []  # è®°å½•å·¥å…·è°ƒç”¨
                print("\n=== Claude åˆ†æç»“æœ ===\n")

                async for message in client.receive_response():
                    if hasattr(message, "content"):
                        for block in message.content:
                            # æ£€æŸ¥å·¥å…·è°ƒç”¨
                            if hasattr(block, "type") and block.type == "tool_use":
                                tool_info = {
                                    "name": getattr(block, "tool_name", "unknown"),
                                    "input": getattr(block, "input", {}),
                                }
                                tool_calls.append(tool_info)
                                print(f"\nğŸ”§ [å·¥å…·è°ƒç”¨] {tool_info['name']}")
                                # æ‰“å°å·¥å…·å‚æ•°ï¼ˆç®€åŒ–æ˜¾ç¤ºï¼‰
                                if tool_info["name"] == "read":
                                    file_path = tool_info["input"].get("file_path", "")
                                    print(f"   ğŸ“„ è¯»å–æ–‡ä»¶: {file_path}")
                                elif tool_info["name"] == "grep":
                                    pattern = tool_info["input"].get("pattern", "")
                                    print(f"   ğŸ” æœç´¢: {pattern}")
                                elif tool_info["name"] == "glob":
                                    pattern = tool_info["input"].get("pattern", "")
                                    print(f"   ğŸ“ æŸ¥æ‰¾æ–‡ä»¶: {pattern}")
                                print()

                            # æ”¶é›†æ–‡æœ¬å†…å®¹
                            if hasattr(block, "text"):
                                analysis_result += block.text
                                print(block.text, end="", flush=True)

                print(f"\n\n=== åˆ†æå®Œæˆ ===\n")

                # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ç»Ÿè®¡
                if tool_calls:
                    print(f"ğŸ“Š å·¥å…·è°ƒç”¨ç»Ÿè®¡:")
                    print(f"   æ€»è®¡è°ƒç”¨: {len(tool_calls)} æ¬¡")
                    tool_counts = {}
                    for tc in tool_calls:
                        tool_counts[tc["name"]] = tool_counts.get(tc["name"], 0) + 1
                    for tool_name, count in tool_counts.items():
                        print(f"   - {tool_name}: {count} æ¬¡")
                    print()
                else:
                    print("â„¹ï¸  æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")

                # è¿”å›åˆ†æç»“æœ
                return {
                    "success": True,
                    "pr_number": pr_number,
                    "pr_title": target_pr["title"],
                    "analysis": analysis_result,
                    "analyzed_at": datetime.now().isoformat(),
                    "pr_data": target_pr,
                }

        except Exception as e:
            import traceback

            error_details = f"{str(e)}\nTraceback:\n{traceback.format_exc()}"
            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:\n{error_details}")
            return {
                "success": False,
                "pr_number": pr_number,
                "pr_title": target_pr.get("title", ""),
                "error": str(e),
                "error_details": error_details,
                "analyzed_at": datetime.now().isoformat(),
            }

    def close(self):
        """
        å…³é—­æ•°æ®åº“è¿æ¥
        """
        if self.db:
            self.db.close()


async def main():
    """
    ä¸»å‡½æ•° - ç»Ÿä¸€å…¥å£ï¼Œæ”¯æŒé€‰æ‹©ä½¿ç”¨ ClaudeSDKClient æˆ– Anthropic API
    """
    analyzer = PRAnalysisWithClaude()

    try:
        print("ğŸš€ IoTDB PR åˆ†æå·¥å…·")
        print("=" * 60)
        print("è¯·é€‰æ‹©åˆ†ææ–¹å¼ï¼š")
        print("1. ä½¿ç”¨ ClaudeSDKClient (æ”¯æŒå·¥å…·è°ƒç”¨ã€è¯»å–æºç )")
        print("2. ä½¿ç”¨ Anthropic API (æ”¯æŒå·¥å…·è°ƒç”¨ + cache_control)")
        print("=" * 60)

        # è·å–ç”¨æˆ·é€‰æ‹©
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1 æˆ– 2): ").strip()

        if choice not in ["1", "2"]:
            print("âŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
            return

        # è·å– PR ç¼–å·
        # pr_number = 14591  # Memory table
        # pr_number = 16487 #
        pr_number = 15685  # Insert into

        print("\n" + "=" * 60)

        if choice == "1":
            # ä½¿ç”¨ ClaudeSDKClient
            print("ğŸš€ å¼€å§‹PRåˆ†æ (ä½¿ç”¨ ClaudeSDKClient - æ”¯æŒå·¥å…·è°ƒç”¨)...")
            result = await analyzer.analyze_pr_with_cc_sdk(pr_number=pr_number)

            if result["success"]:
                print(f"\nâœ… åˆ†æå®Œæˆï¼")
                print(f"PR #{result['pr_number']}: {result['pr_title']}")
                print(f"\nåˆ†æç»“æœ:\n{result['analysis']}")
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥: {result['error']}")
                if "error_details" in result:
                    print(f"\nè¯¦ç»†é”™è¯¯:\n{result['error_details']}")

        else:  # choice == "2"
            # ä½¿ç”¨ Anthropic APIï¼ˆé»˜è®¤å¯ç”¨å·¥å…·å’Œç¼“å­˜ï¼‰
            print("ğŸš€ å¼€å§‹PRåˆ†æ (ä½¿ç”¨ Anthropic API + å·¥å…·è°ƒç”¨ + Cache Control)...")

            result = await analyzer.analyze_pr_with_anthropic(
                pr_number=pr_number,
                enable_tools=True,  # é»˜è®¤å¯ç”¨å·¥å…·
                use_cache=True,  # é»˜è®¤å¯ç”¨ç¼“å­˜
            )

            if result["success"]:
                print(f"\nâœ… åˆ†æå®Œæˆï¼")
                print(f"PR #{result['pr_number']}")

                # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
                usage = result.get("usage", {})
                print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
                print(f"   è¾“å…¥ tokens: {usage.get('input_tokens', 0):,}")
                print(f"   è¾“å‡º tokens: {usage.get('output_tokens', 0):,}")
                print(f"   ç¼“å­˜åˆ›å»º: {usage.get('cache_creation_tokens', 0):,}")
                print(f"   ç¼“å­˜è¯»å–: {usage.get('cache_read_tokens', 0):,}")
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥: {result['error']}")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except ValueError:
        print("\nâŒ PR ç¼–å·å¿…é¡»æ˜¯æ•°å­—")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
    finally:
        analyzer.close()


if __name__ == "__main__":
    asyncio.run(main())
