#!/usr/bin/env python3
"""
æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹ï¼šåˆ†æPRå¹¶ä½¿ç”¨å‘é‡æ•°æ®åº“æœç´¢
"""

import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import asyncio
import json
from pr_analysis_with_claude import PRAnalysisWithClaude
from vector_store import VectorStoreManager


async def demo_workflow():
    """æ¼”ç¤ºå®Œæ•´çš„PRåˆ†æå’Œæœç´¢å·¥ä½œæµç¨‹"""

    print("=" * 80)
    print("IoTDB PRåˆ†æå·¥å…· - å®Œæ•´å·¥ä½œæµç¨‹æ¼”ç¤º")
    print("=" * 80)

    # æ­¥éª¤1: åˆå§‹åŒ–åˆ†æå™¨å’Œå‘é‡æ•°æ®åº“
    print("\næ­¥éª¤1: åˆå§‹åŒ–PRåˆ†æå™¨å’Œå‘é‡æ•°æ®åº“")
    print("-" * 80)
    analyzer = PRAnalysisWithClaude()
    vector_store = VectorStoreManager()

    # æ­¥éª¤2: åˆ†æä¸€ä¸ªPR
    print("\næ­¥éª¤2: åˆ†æPR #16487")
    print("-" * 80)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
    import os

    analysis_file = "pr_16487_analysis.json"

    if os.path.exists(analysis_file):
        print(f"âœ… å‘ç°å·²æœ‰åˆ†æç»“æœ: {analysis_file}")
        with open(analysis_file, "r", encoding="utf-8") as f:
            result = json.load(f)
        print(f"PR #{result['pr_number']}: {result['pr_title']}")
        print(f"åˆ†ææ—¶é—´: {result['analyzed_at']}")

        # ç¡®ä¿å·²æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        print("\næ­£åœ¨ç¡®ä¿åˆ†æç»“æœå·²æ·»åŠ åˆ°å‘é‡æ•°æ®åº“...")
        vector_store.add_pr_analysis(
            pr_number=result["pr_number"],
            pr_title=result["pr_title"],
            analysis=result["analysis"],
            metadata={"analyzed_at": result["analyzed_at"]},
        )
    else:
        print("æ­£åœ¨è°ƒç”¨Claudeåˆ†æPR...")
        result = await analyzer.analyze_pr_with_anthropic(pr_number=16487)

        if result["success"]:
            print(f"âœ… åˆ†ææˆåŠŸ!")
            print(f"PR #{result['pr_number']}: {result['pr_title']}")

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(analysis_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
        else:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
            analyzer.close()
            return

    # æ­¥éª¤3: æŸ¥çœ‹å‘é‡æ•°æ®åº“ç»Ÿè®¡
    print("\næ­¥éª¤3: æŸ¥çœ‹å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("-" * 80)
    stats = vector_store.get_collection_stats()
    print(f"é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
    print(f"æ€»æ–‡æ¡£æ•°: {stats.get('total_documents', 0)}")
    print(f"å­˜å‚¨è·¯å¾„: {stats.get('persist_directory', 'N/A')}")

    # æ­¥éª¤4: æ‰§è¡Œè¯­ä¹‰æœç´¢
    print("\næ­¥éª¤4: æ‰§è¡Œè¯­ä¹‰æœç´¢")
    print("-" * 80)

    # å®šä¹‰ä¸€äº›æœç´¢æŸ¥è¯¢
    search_queries = [
        "JDBCé…ç½®é”™è¯¯",
        "Mavenæ„å»ºé—®é¢˜",
        "feature.xmlæ–‡ä»¶è·¯å¾„",
    ]

    for query in search_queries:
        print(f"\nğŸ” æœç´¢: '{query}'")
        print("  " + "-" * 76)

        results = vector_store.search_with_score(query, k=2)

        if results:
            for idx, (doc, score) in enumerate(results, 1):
                pr_num = doc.metadata.get("pr_number")
                pr_title = doc.metadata.get("pr_title")
                chunk_idx = doc.metadata.get("chunk_index", 0)
                print(
                    f"  ç»“æœ {idx}: PR #{pr_num} - {pr_title} (ç›¸ä¼¼åº¦: {score:.4f}, æ–‡æ¡£å—: {chunk_idx+1})"
                )
                # æ˜¾ç¤ºå†…å®¹ç‰‡æ®µ
                content_preview = doc.page_content[:1000].replace("\n", " ")
                print(f"    å†…å®¹: {content_preview}...")
        else:
            print("  æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")

    # æ­¥éª¤5: æ€»ç»“
    print("\n" + "=" * 80)
    print("æ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)
    print("\næ¥ä¸‹æ¥ä½ å¯ä»¥:")
    print("1. ä½¿ç”¨ search_pr_analysis.py è¿›è¡Œæ›´å¤šæœç´¢")
    print("2. åˆ†ææ›´å¤šPRä»¥ä¸°å¯Œå‘é‡æ•°æ®åº“")
    print("3. æŸ¥çœ‹ VECTOR_STORE_README.md äº†è§£æ›´å¤šåŠŸèƒ½")
    print("=" * 80)

    # æ¸…ç†
    analyzer.close()


async def quick_search_demo():
    """å¿«é€Ÿæœç´¢æ¼”ç¤º"""
    print("\n" + "=" * 80)
    print("å¿«é€Ÿæœç´¢æ¼”ç¤º")
    print("=" * 80)

    vector_store = VectorStoreManager()

    query = "å¦‚ä½•ä¿®å¤æ„å»ºé”™è¯¯"
    print(f"\næœç´¢æŸ¥è¯¢: '{query}'")
    print("-" * 80)

    results = vector_store.search_similar_prs(query, k=3)

    if results:
        for idx, result in enumerate(results, 1):
            print(f"\nç»“æœ {idx}:")
            print(f"  PR #{result['pr_number']}: {result['pr_title']}")
            print(f"  å†…å®¹ç‰‡æ®µ: {result['content'][:1000]}...")
    else:
        print("æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")


if __name__ == "__main__":
    import sys

    try:
        if len(sys.argv) > 1 and sys.argv[1] == "search":
            # å¿«é€Ÿæœç´¢æ¨¡å¼
            asyncio.run(quick_search_demo())
        else:
            # å®Œæ•´æ¼”ç¤ºæ¨¡å¼
            asyncio.run(demo_workflow())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
