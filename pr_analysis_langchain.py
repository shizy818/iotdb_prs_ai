#!/usr/bin/env python3
"""
ä½¿ç”¨ LangChain å®ç° PR åˆ†æ
é›†æˆ LangChain çš„å·¥å…·å’Œ Agent èƒ½åŠ›
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import BaseTool, StructuredTool
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel, Field

from database import DatabaseManager


class ReadFileInput(BaseModel):
    """è¯»å–æ–‡ä»¶çš„è¾“å…¥å‚æ•°"""

    file_path: str = Field(
        description="è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¦‚ 'iotdb-core/datanode/src/main/java/org/apache/iotdb/db/queryengine/execution/operator/process/TableIntoOperator.java'ï¼‰"
    )


class GlobInput(BaseModel):
    """Glob æŸ¥æ‰¾æ–‡ä»¶çš„è¾“å…¥å‚æ•°"""

    pattern: str = Field(
        description="Glob æ¨¡å¼ï¼ˆå¦‚ '**/*TableIntoOperator*.java', '**/*.xml'ï¼‰"
    )
    path: str = Field(
        default="", description="æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•ï¼‰"
    )


class GrepInput(BaseModel):
    """Grep æœç´¢çš„è¾“å…¥å‚æ•°"""

    pattern: str = Field(description="æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰")
    path: str = Field(default="", description="æœç´¢è·¯å¾„ï¼Œç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼‰")
    file_type: str = Field(default="", description="æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ 'java', 'py', 'xml'ï¼‰ï¼ˆå¯é€‰ï¼‰")


def _build_analysis_prompt(pr_data: Dict, diff_content: str) -> str:
    """
    æ„å»ºPRåˆ†ææç¤º

    Args:
        pr_data: PRæ•°æ®
        diff_content: diffå†…å®¹

    Returns:
        åˆ†ææç¤ºå­—ç¬¦ä¸²
    """
    # æ„å»ºè¯„è®ºéƒ¨åˆ†
    if pr_data.get("comments"):
        comments_section = "- PR è®¨è®ºè¯„è®º\n"
        for idx, comment in enumerate(pr_data["comments"], 1):
            comment_time = comment.get("created_at", "")
            comment_user = comment.get("user", "æœªçŸ¥ç”¨æˆ·")
            comment_body = comment.get("body", "")
            comments_section += f"""  è¯„è®º {idx} (ä½œè€…: {comment_user}, æ—¶é—´: {comment_time}):
{comment_body}
---
"""
    else:
        comments_section = "- PR è®¨è®ºè¯„è®º: æ— \n"

    template = """
IoTDB PRè¯¦ç»†ä¿¡æ¯ï¼š
- ç¼–å·: {number}
- æ ‡é¢˜: {title}
- æè¿°: {body}
- åˆ›å»ºæ—¶é—´: {created_at}
- åˆå¹¶æ—¶é—´: {merged_at}
- ä½œè€…: {user}
- æ ‡ç­¾: {labels}
- ä»£ç å˜æ›´: +{additions} è¡Œ, -{deletions} è¡Œ
- åˆ†æ”¯: {head} -> {base}
- Diffé“¾æ¥: {diff_url}
{comments_section}

è¿™æ˜¯ä¸€ä¸ªIoTDBçš„Pull Requestï¼Œè¯·å…ˆé˜…è¯»ä¸Šè¿°åŸºæœ¬ä¿¡æ¯ã€‚æ¥ä¸‹æ¥æ˜¯ä»£ç å˜æ›´çš„diffå†…å®¹ï¼š

```diff
{diff_content}
```

ç°åœ¨ä½ å·²ç»æ”¶åˆ°äº†å®Œæ•´çš„PRä¿¡æ¯ï¼ˆåŒ…æ‹¬åŸºæœ¬ä¿¡æ¯å’Œdiffå†…å®¹ï¼‰ã€‚

**é‡è¦ï¼šåœ¨åˆ†æä¹‹å‰ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨ä»¥ä¸‹å·¥å…·è¯»å–ç›¸å…³æºç æ–‡ä»¶ä»¥ä¾¿æ·±å…¥ç†è§£ï¼š**
1. ä½¿ç”¨ glob å·¥å…·æŸ¥æ‰¾ diff ä¸­æ¶‰åŠçš„æºç æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼š`**/ClassName.java`ï¼‰
2. ä½¿ç”¨ read å·¥å…·è¯»å–è¿™äº›å®Œæ•´çš„æºç æ–‡ä»¶
3. ä½¿ç”¨ grep å·¥å…·æœç´¢ç›¸å…³çš„ç±»ã€æ–¹æ³•æˆ–å…³é”®å­—ä»¥è·å–æ›´å¤šä¸Šä¸‹æ–‡

**ç„¶åè¿›è¡Œæ·±å…¥åˆ†æï¼š**
1. è¿™ä¸ªPRå…·ä½“è§£å†³äº†ä»€ä¹ˆæŠ€æœ¯é—®é¢˜ï¼Ÿ
2. å¦‚æœå®¢æˆ·ç¯å¢ƒæ²¡æœ‰è¿™ä¸ªä¿®å¤ï¼Œç³»ç»Ÿå¯èƒ½å‡ºç°ä»€ä¹ˆå…·ä½“é”™è¯¯ï¼Ÿ
3. å¯èƒ½å‡ºç°çš„é”™è¯¯ä¿¡æ¯ã€å¼‚å¸¸å †æ ˆæˆ–æ—¥å¿—æ˜¯ä»€ä¹ˆï¼Ÿ
4. å¯¹ç³»ç»Ÿç¨³å®šæ€§ã€æ€§èƒ½å’ŒåŠŸèƒ½çš„å½±å“ç¨‹åº¦ï¼Ÿ
5. å»ºè®®çš„ä¸´æ—¶è§£å†³æ–¹æ¡ˆæˆ–è§„é¿æªæ–½ï¼Ÿ
6. æ¨èçš„å‡çº§ä¼˜å…ˆçº§ï¼Ÿ

è¯·æä¾›è¯¦ç»†ã€ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚"""

    return template.format(
        number=pr_data.get("number", ""),
        title=pr_data.get("title", ""),
        body=pr_data.get("body", "æ— æè¿°"),
        created_at=pr_data.get("created_at", ""),
        merged_at=pr_data.get("merged_at", ""),
        user=pr_data.get("user", ""),
        labels=json.dumps(pr_data.get("labels", []), ensure_ascii=False),
        additions=pr_data.get("additions", 0),
        deletions=pr_data.get("deletions", 0),
        head=pr_data.get("head", ""),
        base=pr_data.get("base", ""),
        comments_section=comments_section,
        diff_url=pr_data.get("diff_url", "æ— "),
        diff_content=diff_content if diff_content else "æ— ä»£ç å˜æ›´",
    )


class PRAnalysisLangChain:
    """ä½¿ç”¨ LangChain å®ç°çš„ PR åˆ†æå™¨"""

    def __init__(
        self, iotdb_source_dir: str = "/Users/shizy/projects/iotdb_issues_ai/iotdb"
    ):
        """
        åˆå§‹åŒ– PR åˆ†æå™¨

        Args:
            iotdb_source_dir: IoTDB æºç ç›®å½•è·¯å¾„
        """
        self.db = DatabaseManager()
        self.iotdb_source_dir = Path(iotdb_source_dir)

        # è®¾ç½® Anthropic API
        os.environ["ANTHROPIC_BASE_URL"] = "https://open.bigmodel.cn/api/anthropic"
        os.environ["ANTHROPIC_API_KEY"] = "9be7a6c89bfc4cd99efb491c77140aa4.GI2bDndwSd7hqy69"

        # åˆå§‹åŒ– LangChain èŠå¤©æ¨¡å‹
        self.llm = ChatAnthropic(
            model="glm-4-plus",
            # model="claude-sonnet-4-5-20250929",
            temperature=0.3,
            max_tokens=16384,
        )

        # åˆ›å»ºå·¥å…·
        self.tools = self._create_tools()

    def _create_read_tool(self) -> BaseTool:
        """åˆ›å»ºè¯»å–æ–‡ä»¶çš„å·¥å…·"""

        def read_file(file_path: str) -> str:
            """
            è¯»å– IoTDB æºç æ–‡ä»¶çš„å†…å®¹

            Args:
                file_path: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼‰

            Returns:
                å®Œæ•´æ–‡ä»¶å†…å®¹ï¼ˆç»™æ¨¡å‹åˆ†æç”¨ï¼‰
            """
            try:
                full_path = self.iotdb_source_dir / file_path
                if not full_path.exists():
                    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    return f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

                # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆé™åˆ¶å¤§å°ï¼‰
                with open(full_path, "r", encoding="utf-8") as f:
                    content = f.read(500000)  # é™åˆ¶ 500KB

                # æ§åˆ¶å°åªæ˜¾ç¤ºç®€è¦ä¿¡æ¯
                file_size = len(content)
                line_count = content.count('\n') + 1
                print(f"ğŸ“– å·²è¯»å–æ–‡ä»¶: {file_path} ({file_size:,} å­—ç¬¦, {line_count:,} è¡Œ)")

                # è¿”å›å®Œæ•´å†…å®¹ç»™æ¨¡å‹
                return content
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}")
                return f"é”™è¯¯: è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"

        return StructuredTool.from_function(
            func=read_file,
            name="read",
            description="è¯»å– IoTDB æºç æ–‡ä»¶çš„å†…å®¹ã€‚æ–‡ä»¶è·¯å¾„ç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ã€‚",
            args_schema=ReadFileInput,
        )

    def _create_glob_tool(self) -> BaseTool:
        """åˆ›å»º Glob æŸ¥æ‰¾æ–‡ä»¶çš„å·¥å…·"""

        def glob_files(pattern: str, path: str = "") -> str:
            """
            ä½¿ç”¨ glob æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶

            Args:
                pattern: Glob æ¨¡å¼ï¼ˆå¦‚ '**/*.java'ï¼‰
                path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼‰

            Returns:
                åŒ¹é…çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆJSON æ ¼å¼ï¼‰
            """
            try:
                search_dir = (
                    self.iotdb_source_dir / path if path else self.iotdb_source_dir
                )
                matches = list(search_dir.glob(pattern))

                # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                relative_paths = [
                    str(p.relative_to(self.iotdb_source_dir)) for p in matches[:100]
                ]  # é™åˆ¶ 100 ä¸ªç»“æœ

                # æ§åˆ¶å°æ˜¾ç¤ºæœç´¢ç»“æœ
                search_path = f"è·¯å¾„: {path if path else 'æ ¹ç›®å½•'}"
                print(f"ğŸ” Glob æœç´¢ '{pattern}' {search_path} -> æ‰¾åˆ° {len(relative_paths)} ä¸ªæ–‡ä»¶")

                result = {
                    "success": True,
                    "matches": relative_paths,
                    "count": len(relative_paths),
                }
                return json.dumps(result, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"âŒ Glob æœç´¢å¤±è´¥: {pattern} - {str(e)}")
                return json.dumps(
                    {"success": False, "error": f"Glob æœç´¢å¤±è´¥: {str(e)}"}
                )

        return StructuredTool.from_function(
            func=glob_files,
            name="glob",
            description="ä½¿ç”¨ glob æ¨¡å¼æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶ã€‚æ”¯æŒ ** é€šé…ç¬¦ã€‚",
            args_schema=GlobInput,
        )

    def _create_grep_tool(self) -> BaseTool:
        """åˆ›å»º Grep æœç´¢å·¥å…·"""

        def grep_search(pattern: str, path: str = "", file_type: str = "") -> str:
            """
            åœ¨ IoTDB æºç ä¸­æœç´¢åŒ¹é…çš„å†…å®¹

            Args:
                pattern: æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
                path: æœç´¢è·¯å¾„ï¼ˆç›¸å¯¹äº IoTDB æºç æ ¹ç›®å½•ï¼‰
                file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ 'java', 'py', 'xml'ï¼‰

            Returns:
                æœç´¢ç»“æœï¼ˆJSON æ ¼å¼ï¼‰
            """
            import subprocess

            try:
                search_dir = (
                    self.iotdb_source_dir / path if path else self.iotdb_source_dir
                )

                # æ„å»º rg (ripgrep) å‘½ä»¤
                cmd = ["rg", "--json", pattern, str(search_dir)]
                if file_type:
                    cmd.extend(["--type", file_type])

                # æ‰§è¡Œæœç´¢
                result = subprocess.run(
                    cmd, capture_output=True, text=True, timeout=10
                )

                # è§£æç»“æœ
                matches = []
                for line in result.stdout.strip().split("\n"):
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                        if data.get("type") == "match":
                            match_data = data.get("data", {})
                            file_path = match_data.get("path", {}).get("text", "")
                            line_number = match_data.get("line_number")
                            line_text = (
                                match_data.get("lines", {}).get("text", "").strip()
                            )

                            # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                            if file_path:
                                rel_path = str(
                                    Path(file_path).relative_to(self.iotdb_source_dir)
                                )
                                matches.append(
                                    {
                                        "file": rel_path,
                                        "line": line_number,
                                        "content": line_text,
                                    }
                                )
                    except json.JSONDecodeError:
                        continue

                # æ§åˆ¶å°æ˜¾ç¤ºæœç´¢ç»“æœ
                search_info = f"æ¨¡å¼: '{pattern}'"
                if path:
                    search_info += f", è·¯å¾„: {path}"
                if file_type:
                    search_info += f", ç±»å‹: {file_type}"
                print(f"ğŸ” Grep æœç´¢ {search_info} -> æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")

                result_data = {
                    "success": True,
                    "matches": matches[:50],  # é™åˆ¶ 50 ä¸ªç»“æœ
                    "count": len(matches),
                }
                return json.dumps(result_data, ensure_ascii=False, indent=2)

            except FileNotFoundError:
                print(f"âŒ ripgrep (rg) æœªå®‰è£…ï¼Œè¯·å®‰è£…: brew install ripgrep")
                return json.dumps(
                    {
                        "success": False,
                        "error": "ripgrep (rg) æœªå®‰è£…ï¼Œè¯·å®‰è£…: brew install ripgrep",
                    }
                )
            except Exception as e:
                print(f"âŒ Grep æœç´¢å¤±è´¥: {pattern} - {str(e)}")
                return json.dumps(
                    {"success": False, "error": f"Grep æœç´¢å¤±è´¥: {str(e)}"}
                )

        return StructuredTool.from_function(
            func=grep_search,
            name="grep",
            description="åœ¨ IoTDB æºç ä¸­æœç´¢åŒ¹é…çš„å†…å®¹ã€‚ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ã€‚",
            args_schema=GrepInput,
        )

    def _create_tools(self) -> List[BaseTool]:
        """åˆ›å»ºæ‰€æœ‰å·¥å…·"""
        return [
            self._create_read_tool(),
            self._create_glob_tool(),
            self._create_grep_tool(),
        ]

    def get_pr_by_number(self, pr_number: Optional[int] = None) -> Optional[Dict]:
        """
        ä»æ•°æ®åº“è·å–æŒ‡å®šPRçš„æ•°æ®

        Args:
            pr_number: PRç¼–å·ï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æœ€æ–°çš„PR

        Returns:
            PRæ•°æ®å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        try:
            cursor = self.db.connection.cursor(dictionary=True)

            if pr_number:
                query = """
                SELECT number, title, body, created_at, merged_at, user, labels,
                       head, base, additions, deletions, diff_url, comments_url
                FROM iotdb_prs
                WHERE number = %s
                """
                cursor.execute(query, (pr_number,))
            else:
                query = """
                SELECT number, title, body, created_at, merged_at, user, labels,
                       head, base, additions, deletions, diff_url, comments_url
                FROM iotdb_prs
                ORDER BY merged_at DESC
                LIMIT 1
                """
                cursor.execute(query)

            pr = cursor.fetchone()

            if pr:
                # è§£æJSONæ ¼å¼çš„labels
                if pr["labels"]:
                    try:
                        pr["labels"] = json.loads(pr["labels"])
                    except (json.JSONDecodeError, TypeError):
                        pr["labels"] = []
                else:
                    pr["labels"] = []

                # è·å–å¯¹åº”çš„diffå†…å®¹
                diff_query = """
                SELECT diff_content
                FROM pr_diffs
                WHERE pr_number = %s
                ORDER BY created_at DESC
                LIMIT 1
                """
                cursor.execute(diff_query, (pr["number"],))
                diff_result = cursor.fetchone()

                if diff_result and diff_result["diff_content"]:
                    pr["diff_content"] = diff_result["diff_content"]
                else:
                    pr["diff_content"] = None

                # è·å–å¯¹åº”çš„è¯„è®ºå†…å®¹
                comments_query = """
                SELECT id, user, body, created_at, updated_at, html_url
                FROM pr_comments
                WHERE pr_number = %s
                ORDER BY created_at ASC
                """
                cursor.execute(comments_query, (pr["number"],))
                comments_results = cursor.fetchall()

                if comments_results:
                    pr["comments"] = comments_results
                else:
                    pr["comments"] = []

            cursor.close()
            return pr

        except Exception as e:
            print(f"ä»æ•°æ®åº“è·å–PRæ•°æ®æ—¶å‡ºé”™: {e}")
            return None

    def analyze_pr(
        self, pr_number: Optional[int] = None, verbose: bool = True
    ) -> Dict:
        """
        ä½¿ç”¨ LangChain Agent åˆ†æ PR

        Agent ä¼šåœ¨å•æ¬¡è°ƒç”¨ä¸­è‡ªåŠ¨è¿›è¡Œå¤šè½®å·¥å…·è°ƒç”¨ï¼Œæ¯è½®éƒ½è®°ä½ä¹‹å‰çš„å·¥å…·ç»“æœ

        Args:
            pr_number: PRç¼–å·ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ†ææœ€æ–°çš„PR
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è·å–PRæ•°æ®
        target_pr = self.get_pr_by_number(pr_number)

        if not target_pr:
            if pr_number:
                return {"success": False, "error": f"æœªæ‰¾åˆ°ç¼–å·ä¸º {pr_number} çš„PR"}
            else:
                return {"success": False, "error": "æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°PRæ•°æ®"}

        pr_number = target_pr["number"]
        pr_title = target_pr["title"]

        if verbose:
            print(f"ğŸ” æ­£åœ¨åˆ†æ PR #{pr_number}: {pr_title}")

        try:
            # è·å– diff å†…å®¹
            diff_content = target_pr.get("diff_content", "")
            diff_size = len(diff_content) if diff_content else 0

            if verbose:
                print(f"ğŸ“¦ Diff å¤§å°: {diff_size:,} å­—ç¬¦ (~{diff_size // 4:,} tokens)")

            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = _build_analysis_prompt(target_pr, diff_content)

            if verbose:
                print(f"ğŸ“Š å®Œæ•´æŸ¥è¯¢å¤§å°: {len(analysis_prompt):,} å­—ç¬¦")
                print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨ LangChain Agent è¿›è¡Œåˆ†æ...")
                print("\n=== Claude åˆ†æç»“æœ ===\n")

            # åˆ›å»º Agent æç¤ºæ¨¡æ¿
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "æ‚¨æ˜¯ä¸€åæ—¶åºæ•°æ®åº“IoTDBä¸“å®¶ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å·¥å…·è¯»å–å’Œæœç´¢ IoTDB æºç æ¥è¾…åŠ©åˆ†æã€‚"
                        "è¯·æ ¹æ®æä¾›çš„PRä¿¡æ¯å’Œæœ¬åœ°iotdbæºç è¿›è¡Œæ·±å…¥åˆ†æï¼Œç„¶åæä¾›è¯¦ç»†çš„åˆ†æç»“æœã€‚",
                    ),
                    ("human", "{input}"),
                    MessagesPlaceholder(variable_name="agent_scratchpad"),
                ]
            )

            # åˆ›å»º Agent
            agent = create_tool_calling_agent(self.llm, self.tools, prompt)

            # åˆ›å»º Agent æ‰§è¡Œå™¨
            agent_executor = AgentExecutor(
                agent=agent,
                tools=self.tools,
                verbose=verbose,
                max_iterations=15,
                handle_parsing_errors=True,
            )

            # æ‰§è¡Œåˆ†æ
            result = agent_executor.invoke({"input": analysis_prompt})

            analysis_result = result.get("output", "")

            if verbose:
                print(f"\n\n=== åˆ†æå®Œæˆ ===\n")

            return {
                "success": True,
                "pr_number": pr_number,
                "pr_title": pr_title,
                "analysis": analysis_result,
                "analyzed_at": datetime.now().isoformat(),
                "pr_data": target_pr,
            }

        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}"
            if verbose:
                print(f"âŒ {error_msg}")
                import traceback

                traceback.print_exc()

            return {
                "success": False,
                "pr_number": pr_number,
                "pr_title": target_pr.get("title", ""),
                "error": error_msg,
                "analyzed_at": datetime.now().isoformat(),
            }

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.db:
            self.db.close()


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="IoTDB PRåˆ†æå·¥å…· - ä½¿ç”¨ LangChain å®ç°"
    )
    parser.add_argument("--pr", type=int, help="åˆ†æç‰¹å®šPRç¼–å·")
    parser.add_argument("--output", type=str, help="è¾“å‡ºç»“æœåˆ°JSONæ–‡ä»¶")
    parser.add_argument("--quiet", action="store_false", help="é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹")

    args = parser.parse_args()

    # åˆå§‹åŒ–åˆ†æå™¨
    try:
        analyzer = PRAnalysisLangChain()
        print("âœ… PRåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨ LangChainï¼‰")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    try:
        # åˆ†æPR
        if args.pr:
            print(f"\nğŸ” æ­£åœ¨åˆ†æ PR #{args.pr}...")
        else:
            print(f"\nğŸ” æ­£åœ¨åˆ†ææœ€æ–°PR...")

        result = analyzer.analyze_pr(pr_number=args.pr, verbose=not args.quiet)

        # æ‰“å°ç»“æœ
        print(f"\n{'='*80}")
        if result["success"]:
            print(f"âœ… åˆ†æå®Œæˆäº: {result['analyzed_at']}")
            print(f"PR #{result['pr_number']}: {result['pr_title']}")
            print(f"\nğŸ“‹ åˆ†æç»“æœ:")
            print(f"{'-'*60}")
            print(result["analysis"][0]["text"])
        else:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
        print(f"\n{'='*80}")

        # è¾“å‡ºç»“æœåˆ°æ–‡ä»¶
        if args.output:
            try:
                with open(args.output, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
            except Exception as e:
                print(f"\nâŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

        return 0 if result["success"] else 1

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        return 1
    finally:
        analyzer.close()


if __name__ == "__main__":
    import sys

    sys.exit(main())
